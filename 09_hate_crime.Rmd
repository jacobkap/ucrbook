# Hate Crime Data {#hate_crimes}

```{r, echo=FALSE}
knitr::opts_chunk$set(
  echo    = FALSE,
  warning = FALSE,
  error   = FALSE,
  message = FALSE
)
```

```{r}
hate_crimes <- readRDS("data/ucr_hate_crimes_1991_2022.rds")
```

This dataset covers crimes that are reported to the police and judged by the police to be motivated by hate. More specifically, they are (1) crimes which were (2) motivated - at least in part - by bias towards a certain person or group of people because of characteristics about them such as race, sexual orientation, or religion. The first part is key: incidents must first be crimes—specifically, the types of crimes the FBI includes in this dataset. Actions motivated by bias that do not meet the legal standard of a crime, or fall outside the specific crime categories covered by this data, are not recorded as hate crimes.

For example, if someone yells racial slurs at a Black person, it’s clearly a biased and racist action, but it wouldn’t be included in this data unless it involved a specific crime like intimidation. Racial slurs alone, without additional criminal behavior, are generally not illegal and thus wouldn’t be reported as a hate crime in this dataset. For the second part, the bias motivation, it must be against a group that the FBI includes in this data. For example, when this data collection began in 1991, there was no way to collect information about hate crimes against transgender people specifically. Instead it would be counted in the "Anti-Lesbian, Gay, Bisexual, Or Transgender, Mixed Group (LGBT) bias motivation. So if a transgender person was assaulted or killed because they were transgender, there would not be a way to count that until 2013 when anti-transgender was first recorded in this data. 

In the previous example the offender shouted a racial slur, clear that the actions were motivated by bias. What about a hate crime where there is no explicit evidence of hate? Say, a White man robs a Black man and targets him because he is Black. The offender does not wear any insignia suggesting bias and never says a word to the victim. If the offender is never caught this robbery would not be considered a hate crime as there is no evidence that it is motivated by hate. Even if the offender is caught this would only be considered a hate crime if the police uncover evidence of bias, such as a confession or text messages between the offender and another person explaining why the victim was targeted. I think many - perhaps even most - hate crimes fall into this category. Where it was in fact a hate crime but there is not sufficient evidence - both in terms of evidence the police can gather and even the victim's own perception - that it was a hate crime. 

This data is a more limited measure of hate crimes than it may initially appear. It represents only (some) crimes, motivated by (some) types of hate, that are both reported to the police and where the police have gathered sufficient evidence to determine bias. It is also the dataset with the fewest agencies reporting, with most agencies not reporting any hate crimes to the FBI in a given year. This may be true for most agencies as hate crimes are rare and many agencies are small with relatively few crimes of any type reported. However, there is evidence that some agencies that likely have hate crimes still do not report. This leads to gaps in the data with some states having few agencies that report hate crimes, agencies reporting some bias motivations but not others, and agencies reporting some years but not others. While these problems exist for all of the SRS datasets, it is more severe in this data. This problem is further complicated by hate crimes being rare even in agencies that report them. With such rare events, even minor changes in which agencies report or whether victims report the crime to the police can drastically change the reported number of hate crimes. For these reasons I strongly advise caution to anyone using these data. 

## Agencies reporting

We will start by looking at how many agencies report hate crime each year. This is a bit tricky since there can be multiple ways to examine how agencies report, and since agencies can truly have no hate crimes in a year it is hard to differentiate the true zeroes from the non-reporters. 

Figure \@ref(fig:hateAgencies) shows the number of agencies that report at least one hate crime incident in that year. During the first year of data in 1991 there were about 750 agencies reporting and that grew steadily to about 2,000 agencies in year 2000. From there it increased a bit over the next decade before declining to below 1,750 in the early 2010s and rising again to around 3,000 agencies at the end of our data.

```{r hateAgencies, fig.cap = "The annual number of police agencies that report at least one hate crime incident in that year."}
hate_crimes %>%
  dplyr::filter(hate_crime_incident_present %in% "one or more hate crime incidents present") %>%
  dplyr::distinct(ori, year, .keep_all = TRUE) %>%
  count(year) %>%
  ggplot(aes(x = year, y = n)) +
  geom_line(size = 1.05) +
  xlab("Year") +
  ylab("# of Agencies") +
  theme_crim() +
  scale_y_continuous(labels = scales::comma) +
  expand_limits(y = 0)
```

The 3,000 or so agencies that report each year are not the same every year. Figure \@ref(fig:hateCrimesEver) shows the cumulative number of agencies that have reported at least one hate crime between 1991 and 2022. There is a steady growth in the cumulative number of agencies, with about 350 new agencies each year. In each year some new agencies report hate crimes for the first time while some agencies that reported a hate crime in previous years do not report any hate crimes in the current year.

```{r hateCrimesEver, fig.cap = "The cumulative number of agencies that have reported one or more hate crimes between 1991 and 2022"}
final <- data.frame(year = sort(unique(hate_crimes$year)),
                    total_agencies           = NA,
                    percent_in_previous_year = NA)

old_agencies <- NA
reporting_agencies <- NA
for (i in 1:nrow(final)) {
  temp <- hate_crimes %>%
    filter(year %in% final$year[i],
           hate_crime_incident_present %in% "one or more hate crime incidents present")
  reporting_agencies_temp <- unique(temp$ori)
  
  # If length is 1, then variable is NA
  if (length(reporting_agencies) == 1) {
    reporting_agencies <- reporting_agencies_temp
    old_agencies       <- reporting_agencies_temp
  } else {
    reporting_agencies <- c(reporting_agencies, reporting_agencies_temp)
  }
  reporting_agencies <- unique(reporting_agencies)
  percent_new_in_old <- sum(reporting_agencies_temp %in% old_agencies) / length(old_agencies)
  
  
  final$total_agencies[i] <- length(reporting_agencies)
  final$percent_in_previous_year[i] <- percent_new_in_old

  old_agencies       <- reporting_agencies_temp
}


ggplot(final, aes(x = year, y = total_agencies)) +
  geom_line(size = 1.05) +
  xlab("Year") +
  ylab("# of Agencies") +
  theme_crim() +
  scale_y_continuous(labels = scales::comma) +
  expand_limits(y = 0) +
  scale_x_continuous(breaks = c(1991, 1995, 2000, 2005, 2010, 2015, 2020))

```

Figure \@ref(fig:hateCrimesPreviousYear) puts this into hard numbers by showing the percent of agencies who reported a hate crime in a certain year who *also* reported a hate crime in the previous year. For most years between 50% and 60% of agencies which reported a hate crime in the year shown on the x-axis also reported a hate crime in the previous year, indicating somewhat high consistency in which agencies have hate crimes. 

```{r hateCrimesPreviousYear, fig.cap = "The percent of agencies that report a hate crime in a given year that also reported a hate crime in the previous year, 1992-2022"}
final %>%
  filter(year > 1991) %>%
ggplot(aes(x = year, y = percent_in_previous_year)) +
  geom_line(size = 1.05) +
  xlab("Year") +
  ylab("% Also in Previous Year") +
  theme_crim() +
  scale_y_continuous(labels = scales::percent) +
  expand_limits(y = 0) +
  scale_x_continuous(breaks = c(1992, 1995, 2000, 2005, 2010, 2015, 2020))
```

Another way to understand reporting is to look at the number of reported hate crimes by state and see which states report and which do not. Figure \@ref(fig:hateCrimesMap) does this for 2022 data by showing the number of reported hate crime incidents by state. Unfortunately what we have done here is basically create a population map, though with California as a clear outlier. Counting up and graphing or mapping the number of crimes is a common first response to getting new data but is not actually that helpful. Here we see that the states with the biggest populations - California, New York, Texas,  - have the most hate crimes. To be more useful let us look at state-level reporting after adjusting to the number of agencies in the state and to the civilian population.

```{r, hateCrimesMap, fig.cap="Total reported hate crimes by state, 2022"}
hate_crimes %>%
  dplyr::filter(year %in% 2022,
                !is.na(incident_number),
                !is.na(state)) %>%
  dplyr::count(state) %>%
  ggplot2::ggplot(aes(map_id = state)) + 
  ggplot2::geom_map(aes(fill = n), map = fifty_states, color = "black") + 
  expand_limits(x = fifty_states$long, y = fifty_states$lat) +
  coord_map() +
  scale_x_continuous(breaks = NULL) + 
  scale_y_continuous(breaks = NULL) +
  labs(x = "", y = "", fill = "Hate Crimes") +
  theme(panel.background = element_blank()) +
  fifty_states_inset_boxes() +
  scale_fill_gradient(low = "white", high = "red", breaks = c(10, 250, 500, 750, 1000, 1250, 1500, 1750, 2000)) 

```


We will start with the rate of agencies reporting though this incorrectly assumes that each agency in the state is comparable. For example, say a state has 10 agencies; one that has jurisdiction over 91% of the state's population, and nine that have jurisdiction over 1% of the population each. If the one big agency reports and none of the nine do then we will say that only 10% of agencies report data. But this one covers 91% of the state so this is actually great coverage. Conversely, having that one agency not report means that even with the other nine agencies reporting we actually cover less than one-tenth of the state's population. Still, this is a useful starting point for understanding this data's reporting and usually answering these kinds of questions requires multiple answers that are all wrong in their own way.

Figure \@ref(fig:statePercentReporting) shows the percent of agencies for each state that reported at least one hate crime in 2022. In New Jersey, the state with the highest percent of agencies reporting, 39% of agencies reported at least one hate crime. It is neighboring states of Pennsylvania, Delaware, and New York have a much lower rate of reporting at 4% (the lowest of any state), 11%, and 14%, respectively. This difference is likely due to a 2019 request by the New Jersey Attorney General to police officers that they [https://www.washingtonpost.com/national-security/2022/01/29/hate-crimes-nj-fbi-asian/]("more thoroughly report on bias incidents.") To me this suggests that decisions at the state level can lead to drastic changes in reporting rates by agencies, and is a possible solution to low reporting rates. 

In 15 states, fewer than 10% of agencies reported a hate crime, and in one state (Pennsylvania) fewer than 5% of agencies did so. One interesting finding from this map is the more liberal states - New Jersey, Washington, California, Connecticut, etc. - have the highest share of agencies reporting a hate crime, indicating that the culture of the state may influence either the propensity of hate crimes, whether victims report, whether agencies report hate crimes, or simply that more hate crimes happen in these areas.   

```{r statePercentReporting, fig.cap = "The percent of agencies in each state that reported at least one hate crime in 2022, excluding agencies covered by another agency."}
hate_crimes$hate_crime_binary <- 0
hate_crimes$hate_crime_binary[hate_crimes$hate_crime_incident_present %in% "one or more hate crime incidents present"] <- 1
hate_crimes$ori9 <- gsub("NB", "NE", hate_crimes$ori9)
hate_crimes$state_abb_ori <- substr(hate_crimes$ori9, 1, 2)
temp <- hate_crimes %>%
  dplyr::filter(year %in% 2022,
                !is.na(state_abb_ori),
                is.na(covered_by_ori)) %>%
  dplyr::distinct(ori9, .keep_all = TRUE) %>%
  dplyr::group_by(state_abb_ori) %>%
  dplyr::summarize(prop_reporting = mean(hate_crime_binary)) %>%
  dplyr::mutate(percent_reporting = prop_reporting * 100)
state <- datasets::state.name[match(tolower(temp$state_abb_ori), tolower(datasets::state.abb))]
temp$state <- state
temp <- temp[!is.na(temp$state), ]
temp$state <- tolower(temp$state)

ggplot2::ggplot(temp, aes(map_id = state)) + 
  ggplot2::geom_map(aes(fill = percent_reporting), map = fifty_states, color = "black") + 
  expand_limits(x = fifty_states$long, y = fifty_states$lat) +
  coord_map() +
  scale_x_continuous(breaks = NULL) + 
  scale_y_continuous(breaks = NULL) +
  labs(x = "", y = "", fill = "% of Agencies With a Hate Crime") +
  theme(panel.background = element_blank()) +
  fifty_states_inset_boxes() +
  scale_fill_gradient(low = "white", high = "red", breaks = c(0, 5, 10, 15, 20, 25, 30, 35)) 

```

To examine how population affects our results, Figure \@ref(fig:statePercentReportingPop) shows the percent of each state's population that is covered by an agency that reported at least one hate crime. Results are similar to Figure \@ref(fig:statePercentReporting) but now show that there is more reporting than it appeared in that figure. That is because while not all agencies report a hate crime, the ones that do report are generally larger (in terms of population) than the ones that do not. And that is to be expected since smaller agencies will have fewer crimes than larger ones meaning that it is less likely that have a hate crime.

So measuring by population we see that about half of the people in the country lives in the jurisdiction of an agency which reported at least one hate crime. The average state also covers about half of the population in a hate-crime-reporting agency. The state with the lowest population covered is Mississippi with 17% of its residents in a jurisdiction with an agency reporting data; the state with the highest share is Hawaii at 86%.

Is this good? We do not necessarily want 100% of agencies to report a hate crime since not all agencies will experience a hate crime in their jurisdiction. The ideal dataset would have all hate crimes reported but without knowing how many hates crimes there actually are we cannot tell how well this data captures hate crimes.

This is also a fairly poor measure of reporting as it just measures agencies reporting at least one hate crime. If an agency had many hate crimes but only reported very few - and here let us think about that as both agencies not knowing a crime was a hate crime and also knowing but not reporting a hate crime - that is also quite bad for our understanding of hate crimes. However, it is far more likely that a hate crime is not reported than a non-hate crime being reported as a hate crime. Since we know the likely direction of any errors we can think about this entire dataset as being the lower-bound of hate crime data.

```{r statePercentReportingPop, fig.cap = "The percent of population in each state in agencies that reported at least one hate crime in 2022, excluding agencies that are covered by another agency."}
temp <- hate_crimes %>%
  dplyr::filter(year %in% 2022,
                !is.na(state_abb_ori),
                is.na(covered_by_ori)) %>%
  dplyr::distinct(ori9, .keep_all = TRUE) %>%
  dplyr::group_by(state_abb_ori,
                  hate_crime_binary) %>%
  dplyr::summarize(population = sum(population)) %>%
  pivot_wider(names_from = hate_crime_binary,
              values_from = population) %>%
  rename_all(make_clean_names) 
temp$x0[is.na(temp$x0)] <- 0
temp$x0[is.na(temp$x1)] <- 0

temp$total_population <- temp$x0 + temp$x1
temp$population_share_reported <- temp$x1 / temp$total_population * 100

state <- datasets::state.name[match(tolower(temp$state_abb_ori), tolower(datasets::state.abb))]
temp$state <- state
temp <- temp[!is.na(temp$state), ]
temp$state <- tolower(temp$state)

ggplot2::ggplot(temp, aes(map_id = state)) + 
  ggplot2::geom_map(aes(fill = population_share_reported), map = fifty_states, color = "black") + 
  expand_limits(x = fifty_states$long, y = fifty_states$lat) +
  coord_map() +
  scale_x_continuous(breaks = NULL) + 
  scale_y_continuous(breaks = NULL) +
  labs(x = "", y = "", fill = "% of Population with a Hate Crime") +
  theme(panel.background = element_blank()) +
  fifty_states_inset_boxes() +
  scale_fill_gradient(low = "white", high = "red", breaks = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100)) 


```

## Tree of Life synagogue shooting {#treeOfLife}

One way I like to check the quality of data is to see how it reports something that I know occurred. Here we will look at how the anti-Semitic attack on a synagogue in Pittsburgh was reported. In October of 2018 the deadliest attack on Jewish people in US history occurred at the Tree of Life synagogue in Pittsburgh, PA. There, 11 congregants were murdered, and several other people, including police officers, were injured by the shooter. Yet according to this data, however, those murders never occurred. Not in Pittsburgh at least. No murders with an anti-Jewish bias were reported in Pittsburgh in 2018. Instead, the shooting was reported by the FBI's Pittsburgh field office, which, like many federal agencies that have offices across the country, is included in the data as its own agency.

This is good and bad. Of course it is good that when a crime happens it is reported in the data. The bad part is that it is counted as hate crimes that occurred in the FBI's Pittsburgh agency, and not the Pittsburgh Police Department. Most research occurs at the local level - usually studying an agency or county. So if a study is examining agency-level characteristics that are related to hate crimes it'd almost certainly exclude these murders as they are reported by a federal agency and not the local Pittsburgh agency. 

This also gets complicated as FBI rules say that a crime should be reported by the most local jurisdiction. This is true even when there is overlapping jurisdiction. 11 people were murdered in Pittsburgh, and several Pittsburgh Police officers were injured. That should mean that the crime is reported by Pittsburgh Police, not by the FBI. Pittsburgh does report these murders in their Offenses Known data, making it even more odd that they are Pittsburgh crimes in one dataset and not another.^[The murders of nine Black parishioners in the Emanuel African Methodist Episcopal Church in Charleston, South Carolina, in 2015 was reported by the Charleston Police Department, making it even more inconsistent for when the FBI reports hate crime murders.] 

## Important variables

This data has the standard set of variables describing the agency that is reporting. This includes the agency ORI - which is the unique ID for that agency - the agency name, their state, and the population under their jurisdiction. It then has more detailed information about each crime such as what crime happened, what type of bias it involved, where it occurred, and some demographics of the offender.

### Date and time

This data says the exact date that the hate crime occurred on - though not the date it was reported on. Figure \@ref(fig:hateCrimesByDay) shows the percent of hates crimes between 1991 and 2022 that occurred on each day of the week. Interestingly, the most common days for a hate crime to occur is on Friday, which is also when non-hate crimes most frequently occur. This suggests that hate crimes do follow the same trends - at least partially - as other crimes.

```{r hateCrimesByDay, fig.cap = "The day of the week that hate crimes occurred on, 1991-2022"}
hate_crimes$day_of_week <- factor(hate_crimes$day_of_week,
                                                levels = rev(c("Monday",
                                                               "Tuesday",
                                                               "Wednesday",
                                                               "Thursday",
                                                               "Friday",
                                                               "Saturday",
                                                               "Sunday")))

hate_crimes %>%
  filter(hate_crime_incident_present %in% "one or more hate crime incidents present") %>%
  ggplot2::ggplot(ggplot2::aes(x = day_of_week)) + 
  ggplot2::geom_bar(ggplot2::aes_string(y = "(..count..)/sum(..count..)")) +
  theme_crim() +
  ggplot2::coord_flip() + 
  ggplot2::xlab("") + 
  ggplot2::ylab("") +
  ggplot2::scale_y_continuous(labels = scales::percent)

```

We can also look at which day of the month is most common, as shown in Figure \@ref(fig:hateCrimesByMonthDay). There's no pattern that I can see other than the the 1st of the most has the most hate crimes and the end of the month has the fewest. Not all months have more than 28 days so it makes sense that the 29th, 30th, and 31st are the least common days. Is the 1st of the month really the most dangerous? I think this is likely just a quirk of the data, and is something we also see in NIBRS data. When an agency does not report an actual date they may use the 1st of the month as a placeholder which then looks to us like the 1st is an especially prolific day for hate crimes. 

```{r hateCrimesByMonthDay, fig.cap = "The day of the month that hate crimes occurred on, 1991-2022"}
hate_crimes$mday <- mday(hate_crimes$incident_date)
hate_crimes$mday <- factor(hate_crimes$mday, levels = 31:1)
hate_crimes %>%
  filter(hate_crime_incident_present %in% "one or more hate crime incidents present") %>%
  ggplot2::ggplot(ggplot2::aes(x = mday)) + 
  ggplot2::geom_bar(ggplot2::aes_string(y = "(..count..)/sum(..count..)")) +
  theme_crim() +
  ggplot2::coord_flip() + 
  ggplot2::xlab("") + 
  ggplot2::ylab("") +
  ggplot2::scale_y_continuous(labels = scales::percent)

```

### The bias motivation (who the hate is against)

The most important variable in this data is the "bias motivation" which is the FBI's term for the cause of the hate. A hate crime targeted against Black people would be an "anti-Black" bias motivation. For the police to classify an incident as a hate crime, and to assign a particular bias motivation, the police must have *some* evidence that the crime was motivated by hate. The victim saying that the crime is a hate crime alone is not sufficient - though if large portions of the victim's community believe that the crime is a hate crime, this can be a factor in the police's assessment. 

The evidence required is not major. It includes evidence as explicit as slurs said during an incident and less obvious factors like the crime occurring on an important holiday for that community (e.g. Martin Luther King Day, religious holidays). The FBI also encourages police to consider the totality of the evidence even if none alone strongly suggests that the crime was a hate crime in making their determination about whether the incident was a hate crime or not. This also means that many (perhaps most) hate crimes will not be recorded as hate crimes since there is no evidence that the crime is motivated by hate. 

Consider, for example, a person who is biased against Asian people and decides to rob them because they are Asian. This is clearly a hate crime. And say this persons robs 10 Asian people in 10 different incidents, causing 10 hate crimes. All of the victims report it to the police but only two of them tell the police that they think it was a hate crime; the other eight do not think it is a hate crime. Without additional information the police would likely not report any of these robberies as hate crimes. And if all ten of the victims happened to be surveyed about crime victimization, such as through the Bureau of Justice Statistics' National Crime Victimization Survey, only two of the 10 victims would report being the victim of a hate crime. Using FBI data the anti-Asian hate crimes would be zero; using victimization surveys would undercount anti-Asian hate crimes enormously. This is the main problem with using hate crime data, even with perfect reporting or surveys of everyone possibly victimized we may still be getting data that is completely incorrect.

In the FBI data bias motivation is based on the offender's perceptions of the victim so even if they are incorrect in who their victim is, if they intended to target someone for their perceived group membership, that is still a hate crime. For example, if a person assaults a man because they think he is gay, that is a hate crime because the assault was motivated by hate towards gay people. Whether the victim is actually gay or not is not relevant - the offender perceived him to be gay so it is an anti-gay hate crime. To make this even more complicated, the offender must have committed the crime because they are motivated, at least to some degree, by their bias against the victim. Being biased against the victim but targeting them for some other reason means that the crime is not a hate crime. 

The biases that the FBI includes in this data have grown over time, with new bias motivations being added in 1997, 2012, 2013, and 2015. Table \@ref(tab:hateBiasMotivation) shows each bias motivation in this data, the year it was first reported, how many hate crimes there were for this bias motivation from 1991-2022 and what percent of hate crimes that bias motivation makes up. 

To make the most common bias motivations easier to identify, the table is sorted by the frequency of incidents. The "first year" column reflects the first year that the bias motivation was officially recorded, though some biases may have existed earlier but were not yet captured in the data. The last column in this table shows the percent of hate crime incidents from 1991-2022. 

This sorting makes it easy to see the most common bias motivations, but that is not actually that useful to most people since we usually care more about a rate than a count. For example, according to this table there were almost three times as many anti-Black hate crimes than anti-Jewish hate crimes, showing that anti-Black hate crimes are more of a problem in this country. But this is not right. We cannot just count of the number of offenses or we risk accidentally just measuring the population of these groups. Black people, for example, make up about 14% of the United States population while Jewish people make up about 2%.^[For simplicity I am treating these groups as independent though of course some Black people can be Jewish.] If we adjust the numbers to equalize population then we see that there is a much higher anti-Jewish hate crime rate than anti-Black rate. 

And even this is not that useful since you really need a much deeper dive into the data before pulling out these seemingly simple statistics. For example, maybe areas with more Jewish people have better reporting than areas with more Black people. Or that Jewish victims would report to the police at higher rates than Black victims. Maybe these are both true at certain times between 1992 and 2022 but have changed over the years. It is not hard to think of possible explanations for differences between groups so without running down each of these explanations I recommend caution before putting out even something as seemingly simple at the number of crimes by bias group. 

```{r }
hate_crimes$bias_motivation_offense_1[hate_crimes$bias_motivation_offense_1 %in% "99"] <- NA
temp <- make_frequency_table_year(hate_crimes,
                                  "bias_motivation_offense_1",
                             c("Bias Motivation",
                               "First Year Reported",
                               "# of Incidents",
                               "% of Incidents"))
temp$`Bias Motivation` <- gsub("lgbt", "LGBT", ignore.case = TRUE, temp$`Bias Motivation`)
temp$`First Year Reported`[temp$`Bias Motivation` %in% "Total"] <- ""
temp <- temp %>% arrange(desc(parse_number(`# of Incidents`)))
kableExtra::kbl(temp, 
           #  format = "html",
             digits = 2, 
             align = c("l", "r", "r"),
             #booktabs = TRUE, 
             longtable = TRUE,
             label = "hateBiasMotivation",
             escape = TRUE,
             caption = "The bias motivation for hate crime incidents. In incidents with multiple bias motivation, this shows only the first bias motivation recorded.") %>%
   kable_styling(bootstrap_options = "striped",
                 full_width = FALSE,
                 latex_options = c("hold_position", "repeat_header"))
```

2015 is the year with the most bias additions, as of data through 2022. This year added a number of religions such as Anti-Buddhist, Anti-Sikh, and Anti-Jehovah's Witness. In 2013, anti-Transgender was added and this is the most common of the bias motivations added since data began in 1991 with 1500 hate crimes between 2013-2022 - 0.62% of all hate crime incidents from 1991-2022. That year also added anti-male and Anti-Native Hawaiian or Other Pacific Islander, which is the most recent racial group added. In 2012, anti-gender non-conforming and anti-female were included, while in 1997 both anti-mental and anti-physical disability were added. In part due to having fewer years of data available, these newer bias motivations make up a small percent of total hate crimes. 

The original hate crimes - that is, those in the data in 1991 when this dataset was released - are far more common. The most common bias motivation is anti-Black at 34% of hate crimes, anti-Jewish at 12%, anti-White at 11%, anti-male homosexual (gay) at 10%, anti-Hispanic at 6%, and anti-ethnicity other than Hispanic (this group means a crime against an ethnic group that is not Hispanic, though it is occasionally reported as anti-non-Hispanic which is incorrect.) at 5%. All other bias motivations are less than 5% of hate crimes and consist of a variety of ethnic, racial, religious, or sexual orientation. Some hate crimes can potentially fall in multiple categories. For example, there is a bias motivation of "anti-male homosexual (gay)" and of "anti-lesbian, gay, bisexual, or transgender, mixed group (LGBT)" so there is some overlap between them. When an incident involves multiple bias motivations we can track that in the data as police can report up to 10 bias motivations per incident. In practice, however, most incidents involve only a single bias motivation.

### The crime that occurred

The "crime" part of hate crimes is which criminal offense occurred during the incident. A hateful act where the action is not one of the crimes that the FBI records would not be considered a hate crime. This is likely most common when considering something like a person calling someone by a hateful slur (e.g. "You're a [slur]," "go back to your own country", etc.) but where the action is not technically a crime. Another layer of difficulty in using this data is that not all crimes that the FBI includes were initially included when data become available in 1991. Every several years the FBI adds new crimes to be included in this data. Table \@ref(tab:hateOffense) shows each crime in the data, the first year that this crime was reported, the total number of these crimes reported between 1991 and 2022, and the percent of all incidents this crime makes up.^[This tables uses only the first offense in an incident so counts are slightly lower than if all crimes in every incident is used.] 

Each hate crime incident can cover up to 10 different crimes occurring - for example, a person who burglarizes a synagogue and spray paints a swastika on the wall would have both burglary and vandalism reported in this data. With each crime, this data has the bias motivation for that crime, the location of the crime (in broad categories, not the actual location in the city like a street address would have), and the number of victims for that offense. In practice, in most hate crimes with multiple offenses recorded, the bias motivation, location, and victim count is the same for each offense.

Figure \@ref(fig:crimesPerHateCrime) shows the number of crimes per incident for each hate crime reported between 1991 and 2022. In 96.6% of cases, there is only one offense in that incident.^[In 0.0004% of hate crimes there is no recorded offense. This is not shown in the graph.] This drops sharply to 3.2% of incidents having two offenses, 0.21% having three offenses, 0.019% having four offenses, and 0.002% having five offenses. Even though this data does allow up to 10 offenses per hate crime incident, there has never been a recorded case with more than five offenses. Results are nearly identical when examining the number of bias motivations and locations reported in an incident. 

```{r crimesPerHateCrime, fig.cap ="The number of offenses per hate crime incident."}
hate_crimes$total_offenses <- 0

for (i in 1:10) {
  hate_crimes$total_offenses[!is.na(hate_crimes[, paste0("ucr_offense_code_", i)])] <- hate_crimes$total_offenses[!is.na(hate_crimes[, paste0("ucr_offense_code_", i)])] + 1
}
 
hate_crimes %>%
  filter(hate_crime_incident_present %in% "one or more hate crime incidents present",
         total_offenses != 0) %>%
crimeutils::make_stat_count_plots("total_offenses", count = FALSE, xlab = "Offenses per Incident") +
  scale_x_continuous(breaks = 1:5)
```

Nearly all hate crimes are vandalism/destruction of property (30%), intimidation (30%), and simple assault (20%) or aggravated assault (11%) with no remaining crime making up more than 2% of total hate crimes. 

```{r }
hate_crimes$ucr_offense_code_1[hate_crimes$ucr_offense_code_1 %in% "720"] <- NA
temp <- make_frequency_table_year(hate_crimes, "ucr_offense_code_1",
                             c("Offense",
                               "First Year Reported", 
                               "# of Incidents", 
                               "% of Incidents"))
temp$`First Year Reported`[temp$Offense %in% "Total"] <- ""
temp <- temp %>% arrange(desc(parse_number(`# of Incidents`)))
kableExtra::kbl(temp, 
          #   format = "html",
             digits = 2, 
             align = c("l", "r", "r"),
             #booktabs = TRUE, 
             longtable = TRUE,
             escape = TRUE,
             label = "hateOffense",
             caption = "The offense type for hate crime incidents. In incidents with multiple offense types, this shows only the first offense type recorded.") %>%
   kable_styling(bootstrap_options = "striped", 
                 full_width = FALSE, 
                 latex_options = c("hold_position", "repeat_header"))
```

Agencies that report to the FBI's National Incident-Based Reporting System (NIBRS) can also report bias motivations for their crimes, and these reports are included in this dataset. One tricky thing is that the crimes included are different depending on if the agency reported through NIBRS or to the dataset directly, and are not NIBRS reporting agencies. NIBRS agencies report all of the crimes as the agencies directly submitting SRS data, but have a wider variety of crimes they can report. In practice, however, both NIBRS and SRS reporting agencies can report the most common offenses so there is relatively little difference.

### The location of the crime

This data is interesting because it includes the location - in categories for types of places, not actual addresses - of the incident. This is important since the type of location can be a factor in whether the incident is classified as a hate crime. For example, spray paint on a synagogue or a mosque is much more likely to be a hate crime than spray paint on a wall of an abandoned building. Table \@ref(tab:hateLocations) shows the locations of hate crimes, including the first year that location was reported. Each hate crime incident can have multiple locations (up to ten) since each offense can have its own incident, but in most cases (96.6%) a hate crime only has a single location. 

As with the crime and the bias motivation, the available locations have increased as time went on, though these newer locations are relatively uncommon. One important change in location is that starting in 2010 the location of "school/college" was split to have one location be for elementary and high schools and another location be for colleges and universities. The majority of hate crimes occur in the victim's home (30%), on a road or alley (19%), in an other or unknown location (13%), and in a parking lot or parking garage (6%). All other locations occur in fewer than 5% of hate crimes. 

```{r }
hate_crimes$location_code_offense_1[hate_crimes$location_code_offense_1 %in% "undocumented code v13"] <- NA
temp <- make_frequency_table_year(hate_crimes, "location_code_offense_1",
                             c("Location",
                               "First Year Reported",
                               "# of Incidents",
                               "% of Incidents"))
temp$`First Year Reported`[temp$Location %in% "Total"] <- ""
temp <- temp %>% arrange(desc(parse_number(`# of Incidents`)))
kableExtra::kbl(temp, 
            # format = "html",
             digits = 2, 
             align = c("l", "r", "r"),
             #booktabs = TRUE, 
             longtable = TRUE,
             escape = TRUE,
             label = "hateLocations",
             caption = "The location of hate crime incidents. In incidents with multiple locations, this shows only the first location recorded.") %>%
   kable_styling(bootstrap_options = "striped", 
                 full_width = FALSE, 
                 latex_options = c("hold_position", "repeat_header"))
```

### Number and race of offenders

There are two variables that have information about the people who commit the hate crime: the number of offenders and the race of the offenders. The offender race is recorded as a single value with the race of the group if all are of the same race or it will say a "multi-racial" group if there are offenders of different races. Unfortunately, important information like the age of the offenders, their criminal history, their relationship to the victim, their gender, or whether they are arrested are completely unavailable in this dataset. These variables, however, are available in NIBRS data. 

As shown in Figure \@ref(fig:hateCrimeOffenderNumber), the most common racial group is "unknown" since the police do not know the race of the offenders. Next are White offenders at nearly 40% of hate crimes followed by Black offenders at nearly 13% of hate crimes. The remaining racial groups are rare with about 2% of hate crimes being committed by a multi-racial group of offenders and 0.8 % of hate crimes committed by Asian or Pacific Islander offenders and 0.6 % committed by American Indian or Native Alaskan offenders. Only 0.05% of offenders are Native Hawaiian or Other Pacific Islander.

```{r hateCrimeOffenderRace, fig.cap = "The race of offenders, as a group, for hate crime incidents, 1991-2022."}
hate_crimes %>%
  filter(hate_crime_incident_present %in% "one or more hate crime incidents present") %>%
  tidyr::replace_na(list(offenders_race_as_a_group = "unknown")) %>%
  dplyr::mutate(offenders_race_as_a_group = crimeutils::capitalize_words(offenders_race_as_a_group)) %>%
crimeutils::make_barplots(column = "offenders_race_as_a_group", count = FALSE) +
  ggplot2::scale_y_continuous(labels = scales::percent, 
                expand = c(0, 0)) +
  ylab("% of Hate Crimes")
```

When the police do not have any information about the number of offenders (which is common in cases of property crimes such as vandalism but rare in violent crimes), this data considers that to have zero offenders. The zero is just a placeholder that means that the police do not know how many offenders there are, not that they think there were actually no offenders. Figure \@ref(fig:hateCrimeOffenderNumber) shows the percent of hate crimes from 1991-2022 that have each number of offenders recorded. In the actual data it says the actual number of offenders, with the largest group in the current data going to 99 offenders - in this graph I group 10 or more offenders together for simplicity. I also relabel zero offenders as "Unknown" offenders since that is more accurate. The most common number of offenders per hate crime is one offender, at about 49% of hate crimes from 1991-2022 having only one offender. This drops sharply to 9% of hate crimes having two offenders and continues to drop as the number of offenders increase. However, about a third (36%) of hate crimes have an unknown number of offenders. 

```{r hateCrimeOffenderNumber, fig.cap = "The race of offenders, as a group, for hate crime incidents, 1991-2022."}
temp <- hate_crimes %>%
  filter(hate_crime_incident_present %in% "one or more hate crime incidents present") 
temp$total_offenders[temp$total_offenders >= 10] <- "10 or more"
temp$total_offenders[temp$total_offenders %in% 0] <- "Unknown"
temp$total_offenders <- factor(temp$total_offenders, levels = rev(c(1:9, "10 or more", "Unknown")))
  ggplot2::ggplot(temp, aes(x = total_offenders)) + 
  theme_crim() + 
  ggplot2::coord_flip() +
  ggplot2::xlab("") +
  ggplot2::geom_bar(ggplot2::aes_string(y = "(..count..)/sum(..count..)")) + 
  crimeutils::theme_crim() +
  ggplot2::scale_y_continuous(labels = scales::percent, 
                              expand = c(0, 0)) +
  ylab("% of Hate Crimes")
```

### Number of victims 

When considering the data itself, hate crime data is very similar to most other datasets. It is just the number of crimes that were reported to the police, though with the additional step of having evidence of bias. But the difference in use is that while in other crimes the victim is usually, well, the victim, in hate crimes the victim may be a much wider group. Consider a burglary: the homeowner is the direct victim, as their property was targeted. However, the crime can also affect their neighbors, who may now feel unsafe in their own homes, as well as the victim’s family, who may worry about their safety.

Hate crimes, however, tend to affect not just the direct victim but also the entire targeted group, or at least a broader community. A swastika painted on a synagogue, for example, impacts not only the synagogue's congregation but may instill fear in the broader Jewish community. If a swastika, for example, is spray painted on the front door of a synagogue, who is the victim? Directly it'd be whomever owns the synagogue building. But it also affects all members of that congregation. And what about members of other synagogues in the city? What about Jewish people in the city who do not go to synagogue? Even though only a single crime occurred - a vandalism - it is very difficult to count how many victims there were. Is a swastika on a synagogue worse if the synagogue has a small congregation versus a large one? What if it is in a city with only one synagogue compared to a city with many? Is it worse to have a large swastika than a small one? 

If we are trying to use this data to measure hate against a particular group these are questions we need to answer, but are of course impossible to answer with this data. Remember, all of the FBI data is essentially just abstract contextless numbers in a spreadsheet. This is true for all UCR data but especially so for hate crimes where no two hate crimes are equal. One burglary in City A is about equivalent to one burglary in City B. For hate crimes a single incident may affect far more people in City A than in City B. 

In fact, I would argue that this issue is bad enough that we should be extraordinarily cautious when using this data. Just aggregating up the number of incidents is insufficient to measuring either hate or fear. Sure, you can measure the number of hate crimes reported to the police and where the police found adequate evidence to label the crime as bias motivated. But is that really what you want be measuring when using hate crime data? 

Nonetheless, this is a book about the data. So let us look at one final variable in this data, the number of victims for each incident. This is not going to be true number of people affected by the crime. It is more the number of direct victims for the incident. Whether that is actually better than just counting incidents is dependent on the context of your question and the hate crimes in question. In Figure \@ref(fig:jewishIncidentVictim) I show the annual number of anti-Jewish hate crimes reported by all agencies in the country. As may be expected, there are always more victims than incidents though the trends are extremely similar over the entire period of data. This trend is also present for other bias motivations, such as anti-Black hate crimes shown in Figure \@ref(fig:blackIncidentVictim). 

While this variable is available in the data, I actually think it is best not to use it. I think there is always a danger in being overly precise and, therefore, overly confident about what the data shows. When you use the number of incidents you implicitly allow for each incident to affect multiple people^[One of the points of hate crimes is to cause fear in more than just the direct victim of the crime.] and readers understand that. But if you use this variable and say that "this is the number of victims of this crime" you are implicitly closing that door and therefore being too confident about how many victims of a crime there is. This is especially true for readers who are not paying close attention - such as academics reviewing papers or New York Times reporters - since they may think you are measuring the number of victims in a better way than you actually are. 

```{r jewishIncidentVictim, fig.cap = "The annual number of anti-Jewish hate crime incidents and victims in the United States, 1991-2022."}

jewish_incidents <-
  hate_crimes %>%
  filter(bias_motivation_offense_1 %in% "anti-jewish" |
           bias_motivation_offense_2 %in% "anti-jewish" |
           bias_motivation_offense_3 %in% "anti-jewish" |
           bias_motivation_offense_4 %in% "anti-jewish" |
           bias_motivation_offense_5 %in% "anti-jewish" |
           bias_motivation_offense_6 %in% "anti-jewish" |
           bias_motivation_offense_7 %in% "anti-jewish" |
           bias_motivation_offense_8 %in% "anti-jewish" |
           bias_motivation_offense_9 %in% "anti-jewish" |
           bias_motivation_offense_10 %in% "anti-jewish") %>%
  count(year) %>%
  rename(number_of_incidents = n)


hate_crimes %>%
  mutate(number_of_victims_offense_1 = parse_number(number_of_victims_offense_1)) %>%
  filter(bias_motivation_offense_1 %in% "anti-jewish" |
           bias_motivation_offense_2 %in% "anti-jewish" |
           bias_motivation_offense_3 %in% "anti-jewish" |
           bias_motivation_offense_4 %in% "anti-jewish" |
           bias_motivation_offense_5 %in% "anti-jewish" |
           bias_motivation_offense_6 %in% "anti-jewish" |
           bias_motivation_offense_7 %in% "anti-jewish" |
           bias_motivation_offense_8 %in% "anti-jewish" |
           bias_motivation_offense_9 %in% "anti-jewish" |
           bias_motivation_offense_10 %in% "anti-jewish") %>%
  group_by(year) %>%
  summarize(number_of_victims_offense_1 = sum(number_of_victims_offense_1)) %>%
  left_join(jewish_incidents) %>%
  ggplot(aes(x = year, y = number_of_victims_offense_1)) +
  geom_line(aes(color = "# of Victims"), size = 1.05) +
  geom_line(aes(y = number_of_incidents, color = "# of Incidents"), size = 1.05) +
  xlab("Year") +
  ylab("Anti-Jewish Crimes") +
  theme_crim() +
  scale_color_manual(values = c("# of Incidents" = "#1b9e77",
                                "# of Victims" = "#d95f02")) +
  scale_y_continuous(labels = scales::comma) +
  labs(color = "") +
  expand_limits(y = 0)

```

```{r blackIncidentVictim, fig.cap = "The annual number of anti-Black hate crime incidents and victims in the United States, 1991-2022."}

black_incidents <-
  hate_crimes %>%
  filter(bias_motivation_offense_1 %in% "anti-black" |
           bias_motivation_offense_2 %in% "anti-black" |
           bias_motivation_offense_3 %in% "anti-black" |
           bias_motivation_offense_4 %in% "anti-black" |
           bias_motivation_offense_5 %in% "anti-black" |
           bias_motivation_offense_6 %in% "anti-black" |
           bias_motivation_offense_7 %in% "anti-black" |
           bias_motivation_offense_8 %in% "anti-black" |
           bias_motivation_offense_9 %in% "anti-black" |
           bias_motivation_offense_10 %in% "anti-black") %>%
  count(year) %>%
  rename(number_of_incidents = n)


hate_crimes %>%
  mutate(number_of_victims_offense_1 = parse_number(number_of_victims_offense_1)) %>%
  filter(bias_motivation_offense_1 %in% "anti-black" |
           bias_motivation_offense_2 %in% "anti-black" |
           bias_motivation_offense_3 %in% "anti-black" |
           bias_motivation_offense_4 %in% "anti-black" |
           bias_motivation_offense_5 %in% "anti-black" |
           bias_motivation_offense_6 %in% "anti-black" |
           bias_motivation_offense_7 %in% "anti-black" |
           bias_motivation_offense_8 %in% "anti-black" |
           bias_motivation_offense_9 %in% "anti-black" |
           bias_motivation_offense_10 %in% "anti-black") %>%
  group_by(year) %>%
  summarize(number_of_victims_offense_1 = sum(number_of_victims_offense_1)) %>%
  left_join(black_incidents) %>%
  ggplot(aes(x = year, y = number_of_victims_offense_1)) +
  geom_line(aes(color = "# of Victims"), size = 1.05) +
  geom_line(aes(y = number_of_incidents, color = "# of Incidents"), size = 1.05) +
  xlab("Year") +
  ylab("Anti-Black Crimes") +
  theme_crim() +
  scale_color_manual(values = c("# of Incidents" = "#1b9e77",
                                "# of Victims" = "#d95f02")) +
  scale_y_continuous(labels = scales::comma) +
  labs(color = "") +
  expand_limits(y = 0)
```

