[["index.html", "Uniform Crime Reporting (UCR) Program Data: A Practitioners Guide Chapter 1 Preface 1.1 Motivation 1.2 Structure of the book 1.3 Citing this book 1.4 Sources of UCR data 1.5 Where to find the data used in this book 1.6 NIBRS data 1.7 This book  in one paragraph 1.8 How to contribute to this book", " Uniform Crime Reporting (UCR) Program Data: A Practitioners Guide Jacob Kaplan 2021-04-04 Chapter 1 Preface If youve read an article about crime or arrests in the United States in the last half century, in most cases it was referring to the FBIs Uniform Crime Reporting Program Data, otherwise known as UCR data. UCR data is, with the exception of the more detailed data that only covers murders, a monthly number of crimes or arrests reported to a single police agency which is then gathered by the FBI into one file that includes all reporting agencies. Think of your home town. This data will tell you how many crimes were reported for a small number of crimes or how many people (broken down by age, sex, and race) were arrested for a (larger) set of crimes in that city (if the city has multiple police agencies, it will use the agency which is the primary agency on the case, usually the local police department) in a given month. This is a very broad measure of crime, and its uses in research - or understanding crime at all - is fairly limited. Yet is has become - and will likely remain among researchers for at least the next decade - the most important crime data in the United States. UCR data is important for three reasons: The definitions are standardized and all agencies follow them so you can compare across agencies and over time. The data is available since 1960 so there is a long period of available data. The data is available for most of the 18,000 police agencies in the United States so you can compare across agencies. For most of this book well be discussing the caveats of the above reasons - or, more directly, why these assumptions are wrong - but these are the reasons why the data is so influential. 1.1 Motivation By the end of each chapter you should have a firm grasp on the dataset the covered and how to use it properly. However, this book cant possibly cover every potential use case for the data so make sure to carefully examine the data for your own particular use. This benefits you because youll know your data better and become a better research because of it. This benefits me because itll increase the quality of research in my field. I get a lot of emails from people asking questions about this data so part of my motivation for writing this book is to create a single place that answers as many questions as I can about the data. Again, the UCR data collection are the most commonly used crime datasets and there are still many current papers published with incorrect information about the data (including such simple aspects like what geographic unit data is in and what time unit it is in). So hopefully this book will decrease the number of misconceptions about this data, increasing overall research quality.1 1.2 Structure of the book This remainder of this book will be divided into eight chapters: an intro chapter briefly summarizing each dataset and going over overall issues with UCR data, seven chapters each covering one of the seven UCR datasets, and a final one covering county-level data, a highly flawed but common use of the UCR data. I highly recommend that you start with the intro chapter (Chapter @ref(ucr_general)) since it covers topics that apply to each UCR dataset - such as understanding agency unique identifiers and why the data (correctly) has negative numbers - that wont be covered in individual chapters. Each of the UCR dataset chapters will follow the same format: well start with a history of the data such as when it first because available and important changes in definitions or variables. Well then look at which variables are available, and the most important (or most used) ones. The bulk of each chapter will be exploring the data to understand how reliable it is and what questions we can adequately answer using it. Since manuals are boring, Ill try to include graphs and images to try to alleviate the boredom. That said, I dont think its possible to make it too fun so sorry in advanced. This book is a mix of facts about the data, such as how many years are available, and my opinions about it, such as whether it is reliable. In cases of facts Ill just say a statement - e.g. the offenses data is available since 1960. In cases of opinion Ill temper the statement by saying something like in my opinion or I think or I believe. 1.3 Citing this book If this book was useful in your research, please cite it. To cite this book, please use the below citation: Kaplan J (2021). Uniform Crime Reporting (UCR) Program Data: A Practitioners Guide. https://github.com/jacobkap/ucrbook. BibTeX format: @Book{ title = {Uniform Crime Reporting (UCR) Program Data: A Practitioner's Guide}, author = {Jacob Kaplan}, year = {2021}, url = {https://ucrbook.com}, } 1.4 Sources of UCR data There are a few different sources of UCR data available today. First, and probably most commonly used, is the data put together by the National Archive of Criminal Justice Data (NACJD)). This a team of out of the University of Michigan who manages a huge number of criminal justice datasets and makes them available to the public. If you have any questions about crime data - UCR or other data - I highly recommend you reach out to them for answers. They have a collection of data and excellent documentation available for UCR data available on their site here. One limitation to their data, however, is that each year of data is available as an individual file meaning that youll need to concatenate each year together into a single file. Some years also have different column names (generally minor changes like spelling robbery rob one year and robb the next) which requires more work to standardize before you could concatenate. They also only have data through 2016 which means that the most recent years (UCR data is available through 2019) of data are (as of this writing) unavailable. Next, and most usable for the general public but limited to researchers, is the FBIs official website Crime Data Explorer. On this site you can chose an agency and see annual crime data (remember, UCR data is monthly so this isnt as detailed as it can be) for certain crimes. This is okay for the general public but only provides a fraction of the data available in the actual data so is really not good for researchers. Finally, I have my own collection of UCR data available publicly on openICPSR, a site which allows people to submit their data for public access. For each of these datasets Ive taken the raw data from the FBI (for early years of homicide data this is actually from NACJD since the FBIs raw data is wrong and cant be parsed. For later years of homicide data this is from the FBIs raw data.) and read it into R. Since the data is only available from the FBI as fixed-width ASCII files, I created a setup file (well explain exactly how reading in this kind of data works in the next chapter) and read the data and then very lightly cleaned the data (i.e. only removing extreme outliers like an agency having millions of arsons in a month). For each of these datasets I detail what Ive done to the data and briefly summarize the data (i.e. a very short version of this book) on the datas page on openICPSR. The main advantage is that all my data has standard variable names and column names and, for data that is small enough, provide the data as a single file that has all years. For large datasets like the arrest data I break it down into parts of the data and not all years in a single file. The downside is that I dont provide documentation other than whats on the openICPSR page and only provide data in R and Stata format. I also have a similar site to the FBIs Crime Data Explorer but with more variables available, that site is available here. Its worth mentioning a final source of UCR information. This is the annual Crimes in the United States report released by the FBI each year around the start of October.2 As an example, here is the website for the 2019 report. In this report is summarized data which in most cases estimates missing data and provides information about national and subnational (though rarely city-level) crime data. As with the FBIs site it is only a fraction of the true data available, so is not a very useful source of crime data. Still, this is a very common source of information used by researchers. 1.5 Where to find the data used in this book The data I am using in this book is the cleaned (well discuss in more detail exactly what I did to clean each dataset in the datasets chapter, but the short answer is that I did very little.) and concatenated data that I put together from the raw data that the FBI releases. That data is available on my website here. I am hosting this book through GitHub which has a maximum file size allowed that is far smaller than these data so youll need to go to my site to download the data, its not available through this books GitHub repo. For some examples Im using the data before I cleaned it of outliers (as an example of the outliers present before I removed them) so that data is not publicly available. 1.6 NIBRS data Another source of FBI data, and one sometimes considered part of the UCR data collection, is the National Incident-Based Reporting System (NIBRS) data. Like its name implies this is an incident-level dataset which has detailed information about each incident reported to the police, including incident circumstances, and victim and offender information. This is also the data that the FBI has declared will replace UCR data starting in 2021, meaning that they will no longer collect UCR data and only allow agencies to submit NIBRS data. NIBRS data is a complex and highly rich dataset that deserves its own book to really understand, so I will not be discussing it any further in this book. 1.7 This book  in one paragraph UCR data is complicated and riddled with limitations, so a naive use of it is certainly wrong. In my opinion, the vast majority of papers that use UCR data should have been rejected. They generally only briefly mention that the data used was UCR data and do not discuss issues with the data such as under-reporting, imputation procedures, or missing data. While their results may not change (or at least not change enough to affect the results) once they account for this, the lack of even bothering to discuss these issues is enough of an issue for an immediate desk reject. Surprisingly, this problem is even more severe for the worst UCR data, county-level imputed data and hate crime data, demonstrating that the authors who use that data are generally the ones least qualified (otherwise they wouldnt use it at all) to do so. 1.8 How to contribute to this book If you have any questions, suggestions, or find any issues, please email me at jkkaplan6 [@] gmail.com. For more minor issues like typos or grammar mistakes, you can edit the book directly through its GitHub page. Thatll make an update for me to accept, which will change the book to include your edit. To do that, click the edit button at the top of the site - the button is highlighted in the below figure. You will need to make a GitHub account to make edits. When you click on that button youll be taken to a page that looks like a Word Doc where you can make edits. Make any edits you want and then scroll to the bottom of the page. There you can write a short (please, no more than a sentence or two) description of what youve done and then submit the changes for me to review. Ideally, this will also decrease the number of emails and increase the number of citations I receive. They also release a report about the first 6-months of the most recent year of data before the October release, but this is generally an estimate from a sample of agencies so is far less useful. "],["about-the-author.html", "About the author", " About the author Jacob Kaplan holds a PhD and a masters degree in criminology from the University of Pennsylvania and a bachelors degree in criminal justice from California State University, Sacramento. His research focuses on Crime Prevention Through Environmental Design (CPTED), specifically on the effect of outdoor lighting on crime. He is the author of several R packages that make it easier to work with data, including fastDummies and asciiSetupReader. His website allows easy analysis of crime-related data and he has released over a dozen crime data sets (primarily FBI UCR data) on openICPSR that he has compiled, cleaned, and made available to the public. For a list of papers he has written (including working papers), please see here. For a list of data sets he has cleaned, aggregated, and made public, please see here. For a list of R packages he has created, please see here. "],["ucr-general.html", "Chapter 2 Overview of the Data 2.1 Crimes included in the UCR datasets 2.2 Issues common across UCR datasets 2.3 A summary of each UCR dataset 2.4 How to identify a particular agency (ORI codes) 2.5 The data as you get it from the FBI", " Chapter 2 Overview of the Data One of the first, and most important, questions I think people have about crime is a simple one: is crime going up? Answering it seems simple - you just count up all the crimes that happen in an area and see if that number of bigger than it was in previous times. However, putting this into practice invites a number of questions, all of which affect how we measure crime. First, we need to define what a crime is? Not philosophically what actions are crimes - or what should be crimes - but literally which of the many thousands of different criminal acts (crimes as defined by state law) should be considered in this measure. Should murder count? Most people would say yes. How about jaywalking or speeding? Many would say probably not. Should marital rape be considered a crime? Now, certainly most people (all, I would hope) would say yes. But in much of the United States it wasnt a crime until the 1970s (Bennice and Resick 2003; McMahon-Howard, Clay-Warner, and Renzulli 2009). Next, we have to know what geographic and time unit to measure crimes at since these decisions determine how precise we can measure crime and when it changed. That is, if you are mugged on Jan 1st at exactly 12:15pm right outside your house, how do we record it? Should we be as precise as including the exact time and location (your home address or coordinates for the address)? Out of privacy concerns to the victim, should we only include a larger time unit (such as hour of the day or just the day without any time of day) or a larger geographic unit (such as a Census Tract or the city)? The final question is that when a crime occurs, how do we know? That is, when we want to count how many crimes occurred do we ask people how often theyve been victimized, do we ask people how often they commit a crime, do we look at crimes reported to police, crimes charged in a criminal court? Each of these measures will likely give different answers as to how many crimes occurred. The FBI answered all of these questions in 1929 when they began the Uniform Crime Reporting (UCR) Program Data, or UCR data for short. Crime consists of eight crime categories - murder, rape, robbery, aggravated assault, burglary, motor vehicle theft, theft, and simple assault - that are reported to the police and is collected each month from each agency in the country. These decisions, born primarily out of the resource limitations of 1929 (e.g. no computers), have had a major impact on criminology research. The first seven crime categories - known as Index Crimes or Part 1 crimes (or Part I sometimes) - are the ones used to measure crime in many criminology papers, even when the researchers have access to data that covers a broader selection of crimes than these.3 The crime data actually also includes the final crime, simple assault, though it is not included as an index crime and is, therefore, generally ignored by researchers - a relatively large flaw in most studies that well discuss in more detail in Section @ref(index_crimes). If you think that decisions made nearly a century ago are probably not the most useful for current research - and theyre almost certainly not the decisions that you would have made - then youve struck at the core of this book. As researchers, we are relying on datasets whose creation was made so long ago that 2.1 Crimes included in the UCR datasets UCR data covers only a subset - and for the crime data, a very small subset - of all crimes that can occur. It also only includes crimes reported to the police. So there are two levels of abstraction from a crime occurring to it being included in the data: a crime must occur that is one of the crimes included in the UCR collection (we detail all of these crimes below) and the victim must report the incident to the police. While the crimes included are only a small selection of crimes - which were originally chosen since at the time the UCR was designed these were considered important offenses and among the best reported - this is an important first step to understanding the data. In this section well go over the crimes included in the two main UCR datasets: Offenses Known and Clearances by Arrest and (which I like to call the crime dataset) and the Arrests by Age, Sex, and Race (the arrests dataset). These are the most commonly used UCR datasets and the stolen property and homicide datasets are simply more detailed subsets of these datasets. The hate crime dataset can cover a broader selection of offenses than in the crimes or arrests data, so well discuss those in the hate crimes chapter. 2.1.1 Crimes in the Offenses Known and Clearances by Arrest dataset As mentioned above - and as most criminology papers will tell you - the crimes included in the UCRs Offenses Known and Clearances by Arrest data are the seven index crimes (eight when including arson, though arson is in its own dataset) - homicide, rape, robbery, aggravated assault, burglary, theft, and motor vehicle theft - as well as simple assault. This is true but incomplete. The data also includes subcategories for all crimes other than theft - though theft has its own UCR dataset which goes into detail about the thefts. Both robbery and aggravated assault, for example, have subcategories showing which weapon the offender used (if any) during the crime. This allows for a more detailed understanding of the crime than looking only at the broad category. Im not sure why most research includes only the broader categories and doesnt tend to look at subcategories, but that seems to be the case in most studies that I have read. Some police agencies only report the broader categories and dont report subcategories, but most report subcategories so this is an under-exploited source of data. Homicide Murder and non-negligent manslaughter Manslaughter by negligence Rape Rape Attempted rape Robbery With a firearm With a knife of cutting instrument With a dangerous weapon not otherwise specified Unarmed - using hands, fists, feet, etc. Aggravated assault (assault with a weapon or causing serious bodily injury) With a firearm With a knife of cutting instrument With a dangerous weapon not otherwise specified Unarmed - using hands, fists, feet, etc. Burglary With forcible entry Without forcible entry Attempted burglary with forcible entry Theft (other than of a motor vehicle) Motor vehicle theft Cars Trucks and buses Other vehicles Simple Assault 2.1.2 Crimes in the Arrests by Age, Sex, and Race dataset The crimes included in the Arrests by Age, Sex, and Race - the arrest data tells you how many people were arrested for a particular crime category - are different than those in the crime data. The arrest data covers a wider variety of crimes, including drug and alcohol crimes, gambling, and fraud. However, it is also less detailed than the crime dataset when it comes to violent crime. While it covers the same broad categories of violent crimes as the crimes data - murder, rape, robbery, aggravated assault, and simple assault - it doesnt include the more detailed breakdown that is available in the crime data. For example, in the crime data robbery is included as well as the subcategories of robbery with a gun, robbery with a knife, robbery with another dangerous weapon, and robbery without a weapon. In comparison, the arrest data only includes robbery without any subcategories. Homicide Murder and non-negligent manslaughter Manslaughter by negligence Rape Robbery Aggravated assault Burglary Theft (other than of a motor vehicle) Motor vehicle theft Simple assault Arson Forgery and counterfeiting Fraud Embezzlement Stolen property - buying, receiving, and possessing Vandalism Weapons offenses - carrying, possessing, etc. Prostitution and commercialized vice Sex offenses - other than rape or prostitution Drug abuse violations - total Drug sale or manufacturing Opium and cocaine, and their derivatives (including morphine and heroin) Marijuana Synthetic narcotics Other dangerous non-narcotic drugs Drug possession Opium and cocaine, and their derivatives (including morphine and heroin) Marijuana Synthetic narcotics Other dangerous non-narcotic drugs Gambling - total Bookmaking - horse and sports Number and lottery All other gambling Offenses against family and children - nonviolent acts against family members. Includes neglect or abuse, nonpayment of child support or alimony. Driving under the influence (DUI) Liquor law violations - Includes illegal production, possession (e.g. underage) or sale of alcohol, open container, or public use laws. Does not include DUIs and drunkenness. Drunkenness - i.e. public intoxication Disorderly conduct Vagrancy - includes begging, loitering (for adults only), homelessness, and being a suspicious person. All other offenses (other than traffic) - a catch-all category for any arrest that is not otherwise specified in this list. Does not include traffic offenses. Very wide variety of crimes are included - use caution when using! Suspicion - Arrested for no specific offense and released without formal charges being placed. Curfew and loitering law violations - for minors only. Runaways - for minors only. 2.1.3 What is an index (or part 1) crime? One of the first (and seemingly last) thing that people tend to learn about UCR crime data is that it covers something called an index crime.4 Index crimes, sometimes written as Part 1 or Part I crimes, are the seven crimes originally chosen by the FBI to be included in their measure of crimes as these offenses were both considered serious and generally well-reported so would be a useful measure of crime. Index crimes are often broken down into property index crimes - burglary, theft, and motor vehicle theft (and arson now, though thats often not included and is poorly reported) - and violent index crimes (murder, rape, robbery, and aggravated assault). The index is simply that all of the crimes are summed up into a total count of crimes (violent, property, or total) for that police agency. The biggest problem with index crimes is that it is simply the sum of 8 (or 7 since arson data usually isnt available) crimes. Index crimes have a huge range in their seriousness - it includes, for example, both murder and theft - so summing up the crimes gives each crime equal weight. This is clearly wrong as 100 murders is more serious than 100 thefts. This is especially a problem as less serious crimes (theft mostly) are far more common than more serious crimes. In 2017, for example, there were 1.25 million violent index crimes in the United States. That same year had 5.5 million thefts. So using index crimes as your measure of crimes undercounts the seriousness of crimes. Looking at total index crimes is, in effect, mostly just looking at theft. Looking at violent index crimes mostly measures aggravated assault. This is especially a problem because it hides trends in violent crimes. San Francisco, as shown in Figure 2.1, has had a huge increase in index crimes in the last several years. When looking closer, that increase is driven almost entirely by the near doubling of theft since 2011. During the same years, index violent crimes have stayed fairly steady. So the city isnt getting more dangerous - at least not in terms of violent index crimes increasing - but it appears like it is due to just looking at total index crimes. Figure 2.1: Thefts and total index crimes in San Francisco, 1960-2018. While many researchers divide index crimes into violent and nonviolent categories, which helps but even this isnt entirely sufficient. Take Chicago as an example. It is a city infamous for its large number of murders. But as a fraction of index crimes, Chicago has a rounding error worth of murders. Their 653 murders in 2017 is only 0.5% of total index crimes. For violent index crimes, murder makes up 2.2%. As seen in Figure 2.2, in no year where data is available did murders account for more than 3.5% of violent index crimes; and, while murders are increasing as a percent of violent index crimes they still account for no more than 2.5% in most years. What this means is that changes in murder are very difficult to detect. If Chicago had no murders this year, but a less serious crime (such as theft) increased slightly, we couldnt tell from looking at the number of index crimes, even from violent index crimes. As discussed in the below section, using this sample of crimes as the primary measure of crimes - and particularly of violent crimes - is also misleading as it excludes important - and highly common relative to index crimes - offenses, such as simple assault. Figure 2.2: Murders in Chicago as a percent of violent index crimes, 1960-2018. 2.1.3.1 What is a violent crime? An important consideration in using this data is defining what a violent crime is. One definition, and the one that I think makes the most sense, is that a violent crime is one that uses force or the threat of force. For example, if I punch you in the face, that is a violent crime. If I stab you, that is a violent crime. While clearly different in terms of severity, both incidents used force so I believe would be classified as a violent crime. The FBI, and most researchers, reporters, and advocates would disagree. Organizations ranging from the FBI itself to Pew Research Center and advocacy groups like the Vera Institute of Justice and the ACLU all define the first examine as a non-violent crime and the second as a violent crime. They do this for three main reasons. The first reason is that simple assault is not an index crime, so they dont include it when measuring violent crime. It is almost a tautology in criminology that you use index crimes as the measure of crime since thats just what people do. As far as Im aware, this is really the main reason why researchers justify using index crimes: because people in the past used it so thats just what is done now.5 This strikes me as a particularly awful way of doing anything, more so since simple assault data has been available almost as long as index crime data.6 The second reason - and one that I think makes sense for reporters and advocates who are less familiar with the data, but should be unacceptable to researchers - is that people dont know that simple assault is included, or at least dont have easy access to it. Neither the FBIs annual report page not their official crime data tool website include simple assault since they only include index crimes. For people who rely only on these sources - and given that using the data itself requires at least some programming skills, I think this accounts for most users and certainly nearly all non-researchers - it is not possible to access simple assault crime data (arrest data does include simple assault on these sites). The final reason is that it benefits some peoples goals to classify violent crime as only including index crimes. This is because simple assault is extremely common compared to violent index crimes - in many cities simple assault is more common than all violent index crimes put together - so excluding simple assault makes it seem like fewer arrests are violent than they are when including simple assault. For example, a number of articles have noted that marijuana arrests are more common than violent crime arrests (Ingraham 2016; Kertscher 2019; Devito 2020; Earlenbaugh 2020; Edwards et al. 2020) or that violent crime arrests are only 5% of all arrests (Neusteter and OToole 2019; Speri 2019).7 While true when considering only violent index crimes, including simple assault as a violent crime makes these statements false. Some organizations call the violent index crimes serious violent crimes which is an improvement but even this is a misnomer since simple assault can lead to more serious harm than aggravated assault. An assault becomes aggravated if using a weapon or there is the potential for serious harm, even if no harm actually occurs.8 As an example of this last point, 2.3 shows the number of violent index crimes and simple assaults each year from 1960 to 2018 in Houston, Texas (simple assault is not reported in UCR until 1964, which is why 1960-1963 show zero simple assaults). In every year where simple assault is reported, there are more simple assaults than aggravated assaults. Beginning in the late 1980s, there are also more simple assaults than total violent index crimes. Excluding simple assault from the being a violent crime greatly underestimates violence in the country. Figure 2.3: Reported crimes in Philadelphia from 1960 to 2018. Violent index crimes are aggravated assault, rape, robbery, and murder. 2.2 Issues common across UCR datasets In this section well discuss issues common to most or all of the UCR datasets. For some of these, well come back to the issues in more detail in the chapter for the datasets most affected by the problem. 2.2.1 Negative numbers One of the most common questions people have about this data is why there are negative numbers, and if they are a mistake. Negative numbers are not a mistake. The UCR data is monthly so police agencies report the number of monthly crimes that are known to them, either reported to them or discovered by the police. In some cases the police will determine that a crime reported to them didnt actually occur - which they called an unfounded crime. An example that the FBI gives for this is a person reports their wallet stolen (a theft) and then later finds it, so a crime was initially reported but no crime actually occurred. How this works when the police input the data is that an unfounded crime is reported both as an unfounded crime and as a negative actual crime - the negative is used to zero out the erroneous report of the actual crime. So the report would look like 1 actual theft (the crime being reported), -1 theft (the crime being discovered as not have happened), and 1 unfounded theft. If both incidents occurred in the same month then this would simply be a single unfounded theft occurring, with no actual theft - literally a value of 1 + -1 = 0 thefts. Negative values occur when the unfounding happens in a later month than the crime report. In the theft case, lets say the theft occurred in January and the discovery of the wallet happens in August. Assuming no other crimes occurred, January would have 1 theft, and August would have -1 thefts and 1 unfounded theft. There is no way of determining in which month (or even which year) an unfounded crime was initially reported in. When averaging over the long term, there shouldnt be any negative numbers as the actual and unfounded reports will cancel themselves out. However, when looking at monthly crimes - particularly for rare crimes - youll still see negative numbers for this reason. Since crimes can be unfounded for reports in previous years, you can actually see entire years crime counts be negative, though this is much rarer than monthly values.9 2.2.2 Agency population value Each of the UCR datasets include a population variable that has the estimated population under the jurisdiction of that agency.10 This variable is often used to create crime rates that control for population. In cases where jurisdiction overlaps, such as when a city has university police agencies or county sheriffs in counties where the cities in that county have their own police, UCR data assigns the population covered to the most local agency and zero population to the overlapping agency. So an agencys population is the number of people in that jurisdiction that isnt already covered by a different agency. For example, in the city of Los Angeles in California has nearly four million residents according to the US Census. There are multiple police agencies in the city, including the Los Angeles Police Department, the Los Angeles County Sheriffs Office, the California Highway Patrol that operates in the area, airport and port police, and university police departments. If each agency reported the number of people in their jurisdiction - which all overlap with each other - we would end up with a population far higher than LAs four million people. To prevent double-counting population when agencys jurisdictions overlap, the non-primary agency will report a population of 0, even though they still report crime data like normal. As an example, in 2018 California State University - Los Angeles reported 92 thefts and a population of 0. Those 92 thefts are not counted in the Los Angeles Police Department data, even though the department counts the population. To get complete crime counts in Los Angeles, youd need to add up all police agencies within in the city; since the population value is 0 for non-LAPD agencies, both the population and the crime sum will be correct. The UCR uses this method even when only parts of a jurisdiction overlaps. Los Angeles County Sheriff has a population of about one million people, far less than the actual county population (the number of residents, according to the Census) of about 10 million people. This is because the other nine million people are accounted for by other agencies, mainly the local police agencies in the cities that make up Los Angeles County. The population value is the population who reside in that jurisdiction, and does not count people who are in the area but dont live there, such as tourists or people who commute there for work. This means that using the population value to determine a rate can be misleading as some places have much higher numbers of non-residents in the area (e.g. Las Vegas, Washington D.C.) than others. 2.2.3 Reporting is voluntary  so some agencies dont (or report partially) When an agency reports their data to the FBI, they do so voluntarily - there is no nationally requirement to report.11 This means that there is inconsistency in which agencies report, how many months of the year they report for, and which variables they include in their data submissions. This can lead In general, more agencies report their data every year and once an agency begins reporting data they tend to keep reporting. The UCR datasets are a collection of separate, though related, datasets and an agency can report to as many of these datasets as they want - an agency that reports to one dataset does not mean that they report to other datasets. Figure 2.4 shows the number of agencies that submitted at least one month of data to the Offenses Known and Clearances by Arrest data in the given year. For the first decade of available data under 8,000 agencies reported data and this grew to over 13,500 by the late 1970s before plateauing for about a decade. The number of agencies that reported their data actually declined in the 1990s, driven primarily by many Florida agencies temporarily dropping out, before growing steadily to nearly 17,000 agencies in 2010; from here it kept increasing but slower than before. Figure 2.4: The annual number of agencies reporting to the Offenses Known and Clearances by Arrest dataset. Reporting is based on the agency reporting at least one month of data in that year. There are approximately 18,000 police agencies in the United States so recent data has reports from nearly all agencies, while older data has far fewer agencies reporting. When trying to estimate to larger geographies, such as state or national-level, later years will be more accurate as youre missing less data. For earlier data, however, youre dealing with a smaller share of agencies meaning that you have a large amount of missing data and a less representative sample. Figure 2.5 repeats this figure but now including only agencies with 100,000 people or more in their jurisdiction. While these agencies have a far more linear trend than all agencies, the basic lesson is the same: recent data has most agencies reporting; old data excludes many agencies. Figure 2.5: The annual number of agencies with a population of 100,000 or higher reporting to the Offenses Known and Clearances by Arrest dataset. Reporting is based on the agency reporting at least one month of data in that year. This voluntariness extends beyond whether they report or not, but into which variables they report. While in practice most agencies report every crime when they report any, they do have the choice to report only a subset of offenses. This is especially true for subsets of larger categories - such as gun assaults, a subset of aggravated assaults, or marijuana possession which is a subset of drug possession. As an example, Figure 2.6 shows the annual number of aggravated assaults with a gun in New York City. In 2003 the New York Police Department stopped reporting this category of offense, resuming only in 2013. They continued to report the broader aggravated assault category, but not any of the subsections of aggravated assaults which differentiate the weapon used. Figure 2.6: Monthly reports of gun assaults in New York City, 1960-2018. Given that agencies can join or drop out of the UCR program at will, and report only partial data, it is highly important to carefully examine your data to make sure that there are no issues caused by this. Even when an agency reports UCR data, and even when they report every crime category, they can report fewer than 12 months of data. In some cases they simply report all of their data in December, or report quarterly or semi-annually so some months have zero crimes reported while others count multiple months in that months data. One example of this is New York City, shown in Figure 2.7, in the early-2000s to the mid-2010s where they began reporting data quarterly instead of monthly. Figure 2.7: Monthly murders in New York City, 1990-2018. During the 2000s, the police department began reporting quarterly instead of monthly and then resumed monthly reporting. When you sum up each month into an annual count, as shown in Figure 2.8, the problem disappears since the zero months are accounted for in the months that have the quarterly data. If youre using monthly data and only examine the data at the annual level, youll fall into the trap of having incorrect data that is hidden due to the level of aggregation examined. While cases like NYC are obvious when viewed monthly, for people that are including thousands of agencies in their data, it is unfeasible to look at each agency for each crime included. This can introduce errors as the best way to examine the data is manually viewing graphs and the automated method, looking for outliers through some kind of comparison to expected values, can be incorrect. Figure 2.8: Annual murders in New York City, 1990-2018. In other cases when agencies report fewer than 12 months of the year, they simply report partial data and as a result undercount crimes. Figure 2.9 shows annual murders in Miami-Dade, Florida and has three years of this issue occurring. The first two years with this issue are the two where zero murders are reported - this is because the agency didnt report any months of data. The final year is in 2018, the last year of data in this graph, where it looks like murder suddenly dropped significantly. Thats just because Miami-Dade only reported through June, so theyre missing half of 2018. Figure 2.9: Annual murders in Miami-Dade, Florida, 1960-2018. 2.2.4 Zero crimes vs no reports When an agency does not report, we see it in the data as reporting zero crimes, not reporting NA or any indicator that they did not report. In cases where the agency says they didnt report that month we can be fairly sure (not entirely since that variable isnt always accurate) that the zero crimes reported are simply that the agency didnt report. In cases where the agency says they report that month but report zero crimes, we cant be sure if thats a true no crimes reported to the agency or the agency not reporting to the UCR. As agencies can report some crimes but not others in a given month and still be considered reporting that month, just saying they reported doesnt mean that the zero is a true zero. In some cases it is easy to see when a zero crimes reported is actually the agency not reporting. As Figure 2.6 shows with New York City gun assaults, there is a massive and sustained dropoff to zero crimes and then a sudden return years later. Obviously, going from hundreds of crimes to zero crimes is not a matter of crimes not occurring anymore, it is a matter of the agency not reporting - and New York City did report other crimes these years so in the data it says that they reported every month. So in agencies which tend to report many crimes - and many here can be a few as 10 a year since going from 10 to 0 is a big drop - a sudden report of zero crimes is probably just non-reporting. Differentiating zero crimes and no reports becomes tricky in agencies that tend to report few crimes, which most small towns do. As an example, Figure 2.10 shows the annual reports of rape in Danville, California, a city of approximately 45,000 people. The city reports on average 2.8 rapes per year and in five years reported zero rapes. In cases like this its not clear whether we should consider those zero years as true zeros (that no one reported their rape to the police) or whether the agency simply didnt report rape data that year. Figure 2.10: Annual rapes reported in Danville, CA, 1960-2018. 2.3 A summary of each UCR dataset UCR data can be roughly summarized into two groups: crime data and arrest data. While there are several datasets included in the UCR data collection, they are all extensions of one of the above groups. For arrest data, you have information about who (by race and by age-gender, but not by race-gender or race-age other than within race you know if the arrestee is an adult or a juvenile). For crime data, you have monthly counts of a small number of crimes (many fewer than crimes covered in the arrest data) and then more specialized data on a subset of these crimes - information on homicides, hate crimes, assaults or deaths of police officers, and stolen property. Each of these datasets will have its own chapter in this book where we discuss the data thoroughly. Here is a very brief summary of each dataset which will help you know which one to use for your research. I still recommend reading that datas chapter since it covers important caveats and uses (or misuses) of the data that wont be covered below. 2.3.1 Offenses Known and Clearances by Arrest The Offenses Known and Clearances by Arrest dataset - often called Return A, Offenses Known or, less commonly, OKCA - is the oldest and most commonly used dataset and measures crimes reported to the police. For this reason it is used as the main measure of crime in the United States and I tend to call it the crimes dataset. This data includes the monthly number of crimes reported to the police or otherwise known to the police (e.g. discovered while on patrol) for a small selection of crimes, as well as the number of crimes cleared by arrest or by exceptional means (a relatively flawed and manipulable measure of whether the case is solved). It also covers the number reported but found by police to have not occurred. Since this data has monthly agency-level crime information it is often used to measure crime trends between police agencies and over time. The data uses something called a Hierarchy Rule which means that in incidents with multiple crimes, only the most serious is recorded - though in practice this affects only a small percent of cases, and primarily affects property crimes. 2.3.2 Arrests by Age, Sex, and Race The Arrests by Age, Sex, and Race dataset - often called ASR or the arrests data - includes the monthly number of arrests for a variety of crimes and, unlike the crime data, breaks down this data by age and gender. This data includes a broader number of crime categories than the crime dataset (the Offenses Known and Clearances by Arrest data) though is less detailed on violent crimes since it does not breakdown aggravated assault or robberies by weapon type as the Offenses Known data does. For each crime it says the number of arrests for each gender-age group with younger ages (15-24) showing the arrestees age to the year (e.g. age 16) and other ages grouping years together (e.g. age 25-29, 30-34, under 10). It also breaks down arrests by race-age by including the number of arrestees of each race (American Indian, Asian, Black, and White) are the only included races) and if the arrestee is a juvenile (&lt;18 years old) or an adult. The data does technically include a breakdown by ethnicity-age (e.g. juvenile-Hispanic, juvenile-non-Hispanic) but almost no agencies report this data (for many years zero agencies report ethnicity) so in practice the data does not include ethnicity. As the data includes counts of arrestees, people who are arrested multiple times are included in the data multiple times - it is not a measure of unique arrestees. 2.3.3 Law Enforcement Officers Killed and Assaulted (LEOKA) The Law Enforcement Officers Killed and Assaulted data, often called just by its acronym LEOKA, has two main purposes.12 First, it provides counts of employees employed by each agency - broken down by if they are civilian employees or sworn officers, and also broken down by gender. And second, it measures how many officers were assaulted or killed (including officers who die accidentally such as in a car crash) in a given month. The assault data is also broken down into shift type and type (e.g. alone, with a partner, on foot, in a car, etc.), the offenders weapon, and type of call they are responding to (e.g. robbery, disturbance, traffic stop). The killed data simply says how many officers are killed feloniously (i.e. murdered) or died accidentally (e.g. car crash) in a given month. The employee information is at the year-level so you know, for example, how many male police officers were employed in a given year at an agency, but dont know any more than that such as how many officers were on patrol, were detectives, were in special units, etc. This dataset is commonly used as a measure of police employees and is a generally reliable - though imperfect as well see - measure of how many police are employed by a police agency. The second part of this data, measuring assaults and deaths, is more flawed with missing data issues and data error issues (e.g. more officers killed than employed in an agency). 2.3.4 Supplementary Homicide Reports (SHR) The Supplementary Homicide Reports dataset - often abbreviated to SHR - is the most detailed of the UCR datasets and provides information about the circumstances and participants (victim and offender demographics and relationship status) for homicides.13 For each homicide incident it tells you the age, gender, race, and ethnicity of each victim and offender as well as the relationship between the first victim and each of the offenders (but not the other victims in cases where there are multiple victims). It also tells you the weapon used by each offender and the circumstance of the killing, such as a lovers triangle or a gang-related murder. As with other UCR data, it also tells you the agency it occurred in and the month and year when the crime happened. 2.3.5 Hate Crime Data This dataset covers crimes that are reported to the police and judged by the police to be motivated by hate More specifically, they are, first, crimes which were, second, motivated - at least in part - by bias towards a certain person or group of people because of characteristics about them such as race, sexual orientation, or religion. The first part is key, they must be crimes - and really must be the selection of crimes that the FBI collects for this dataset. Biased actions that dont meet the standard of a crime, or are of a crime not included in this data, are not considered hate crimes. For example, if someone yells at a Black person and uses racial slurs against them, it is clearly a racist action. For it to be included in this data, however, it would have to extend to a threat since intimidation is a crime included in this data but lesser actions such as simply insulting someone is not included. For the second part, the bias motivation, it must be against a group that the FBI includes in this data. When this data collection began crimes against transgender people were not counted so if a transgender person was assaulted or killed because they were transgender, this is not a hate crime recorded in the data.14 So this data is really a narrower measure of hate crimes than it might seem. In practice it is (some) crimes motivated by (some) kinds of hate that are reported to the police. It is also the most under-reported UCR dataset with most agencies not reporting any hate crimes to the FBI. This leads to huge gaps in the data with some states having extremely few agencies reporting crime - see, for example Figure 2.11 for state-level hate crimes in 2018 - agencies reporting some bias motivations but not others, agencies reporting some years but not others. While these problems exist for all of the UCR datasets, it is most severe in this data. This problem is exacerbated by hate crimes being rare even in agencies that report them - with such rare events, even minor changes in which agencies report or which types of offenses they include can have large effects. Figure 2.11: Total reported hate crimes by state, 2018. 2.3.6 Property Stolen and Recovered (Supplement to Return A) The Property Stolen and Recovered data - sometimes called the Supplement to Return A (Return A being another name for the Offenses Known and Clearances by Arrest dataset, the crime dataset) - provides monthly information about property-related offenses (theft, motor vehicle theft, robbery, and burglary), including the location of the offense (in broad categories like gas station or residence), what was stolen (e.g. clothing, livestock, firearms), and how much the stolen items were worth.15 Therecovered\" part of this dataset covers the type and value of property recovered so you can use this, along with the type and value of property stolen, to determine what percent and type of items the police managed to recover. Like other UCR datasets this is at the agency-month level so you can, for example, learn how often burglaries occur at the victims home during the day, and if that rate changes over the year or differs across agencies. The data, however, provides no information about the offender or the victim (other than if the victim was an individual or a commercial business [based on the location of the incident - bank, gas station, etc]). The value of the property stolen is primarily based on the victims estimate of how much the item is worth (items that are decreased in value once used - such as cars - are supposed to be valued at the current market rate, but the data provides no indication of when it uses the current market rate or the victims estimate) so it should be used as a very rough estimate of value. 2.3.7 Arson The arson dataset provides monthly counts at the police agency-level for arsons that occur, and includes a breakdown of arsons by the type of arson (e.g. arson of a persons home, arson of a vehicle, arson of a community/public building) and the estimated value of the damage caused by the arson. This data includes all arsons reported to the police or otherwise known to the police (e.g. discovered while on patrol) and also has a count of arsons that lead to an arrest (of at least one person who committed the arson) and reports that turned out to not be arsons (such as if an investigation found that the fire was started accidentally). For each type of arson it includes the number of arsons where the structure was uninhabited or otherwise not in use, so you can estimate the percent of arsons of buildings which had the potential to harm people. This measure is for structures where people normally did not inhabit the structure - such as a vacant building where no one lives. A home where no one is home at the time of the arson does not count as an uninhabited building. In cases where the arson led to a death, that death would be recorded as a murder on the Offenses Known and Clearances by Arrest dataset - but not indicated anywhere on this dataset. If an individual who responds to the arson dies because of it, such as a police officer or a firefighter, this is not considered a homicide (though the officer death is still included in the Law Enforcement Officers Killed and Assaulted data) unless the arsonists intended to cause their deaths. Even though the UCR uses the Hierarchy Rule, where only the most serious offense that occurs is recorded, all arsons are reported - arson is exempt from the Hierarchy Rule. 2.4 How to identify a particular agency (ORI codes) In the UCR and other FBI data sets, agencies are identified using ORiginating Agency Identifiers or an ORI. An ORI is a unique ID code used to identify an agency.16 If we used the agencys name wed end up with some duplicates since there can be multiple agencies in the country (and in a state, those this is very rare) with the same name. For example, if you looked for the Philadelphia Police Department using the agency name, youd find both the Philadelphia Police Department in Pennsylvania and the one in Mississippi. Each ORI is a 7-digit value starting with the state abbreviation (for some reason the FBI incorrectly puts the abbreviation for Nebraska as NB instead of NE) followed by 5 numbers.17 When dealing with specific agencies, make sure to use the ORI rather than the agency name to avoid any mistakes. In this book when discussing a particular agency Ill generally refer to it both by name and by ORI, but in the code used to generate figures and tables I identify that agency through their ORI code.18 For an easy way to find the ORI number of an agency, use this page on my site. Type an agency name or an ORI code into the search section and it will return everything that is a match. 2.5 The data as you get it from the FBI Well finish this overview of the UCR data by briefly talking about format of the data that is released by the FBI, before the processing done by myself or NACJD that converts the data to a type that software like R or Stata or Excel can understand. The FBI releases their data as fixed-width ASCII files which are basically just an Excel file but with all of the columns squished together. As an example, below is the data as you receive it from the FBI for the Offenses Known and Clearances by Arrest dataset for 1960, the first year with data available. In the figure, it seems like there are multiple rows but thats just because the software that I opened the file in isnt wide enough - in reality what is shown is a single row that is extremely wide because there are over 1,500 columns in this data. If you scroll down enough youll see the next row, but that isnt shown in the current image. What is shown is a single row with a ton of columns all pushed up next to each other. Since all of the columns are squished together (the gaps are just blank spaces because the value there is a space, but that doesnt mean there is a in the data. Spaces are possible values in the data and are meaningful), you need some way to figure out which parts of the data belong in which column. Figure 2.12: Fixed-width ASCII file for the 1960 Offenses Known and Clearances by Arrest dataset The fixed-width part of the file type is how this works (the ASCII part basically means its a text file). Each row is the same width - literally the same number of characters, including blank spaces. So you must tell the software you are using to process this file - by literally write code in something called a setup file but is basically just instructions for whatever software you use (R, SPSS, Stata, SAS can all do this) - which characters are certain columns. For example, in this data the first character says which type of UCR data it is (1 means the Offenses Known and Clearances by Arrest data) and the next two characters (in the setup file written as 2-3 since it is characters 2 through 3 [inclusive]) are the state number (01 is the state code for Alabama). So we can read this row as the first column indicating it is an Offenses Known data, the second column indicating that it is for the state of Alabama, and so on for each of the remaining columns. To read in this data youll need a setup file that covers every column in the data (some software, like R, can handle just reading in the specific columns you want and dont need to include every column in the setup file). The second important thing to know about reading in a fixed-width ASCII file is something called a value label.19 For example, in the above image we saw the characters 2-3 is the state and in the row we have the value 01 which means that the state is Alabama. Since this type of data is trying to be as small as efficient as possible, it often replaces longer values with shorter one and provides a translation for the software to use to convert it to the proper value when reading it. Alabama is more characters than 01 so it saves space to say 01 and just replace that with Alabama later on. So 01 would be the value\" and Alabama would be the label that it changes to once read. Fixed-width ASCII files may seem awful to you reading it today, and it is awful to use. But it appears to be an efficient way to store data back many decades ago when data releases began but now is extremely inefficient - in terms of speed, file size, ease of use - compared to modern software so Im not sure why they still release data in this format. But they do, and even the more modern (if starting in 1991, before I was born, is modern!) NIBRS data comes in this format. For you, however, the important part to understand is not how exactly to read this type of data, but to understand that people who made this data publicly available (such as myself and the team at NACJD) must made this conversion process.20 This conversion process, from fixed-width ASCII to a useful format is the most dangerous step taken in using this data - and one that is nearly entirely unseen by researchers. Every line of code you write (or, for SPSS users, click you make) invites the possibility of making a mistake.21 The FBI does not provide a setup file with the fixed-width ASCII data so to read in this data you need to make it yourself. Since some UCR data are massive, this involves assigning the column width for thousands of columns and the value labels for hundreds of different value labels.22 A typo anywhere could have potentially far-reaching consequences, so this is a crucial weakpoint in the data cleaning process - and one in which I have not seen anything written about before. While I have been diligent in checking the setup files and my code to seek out any issues - and I know that NACJD has a robust checking process for their own work - that doesnt mean our work is perfect.23 Even with perfection in processing the raw data to useful files, decisions we make (e.g. what level to aggregate to, what is an outlier) can affect both what type of questions you can ask when using this data, and how well you can answer them. Arson is also an index crime but was added after these initial seven were chosen and is not included in the crimes dataset (though is available separately) so is generally not included in studies that use index crimes. Index crimes are sometimes capitalized as Index Crimes though Ive seen it written both ways. In this book I keep it lowercase as index crimes. Ive also seen the justification that aggravated assault is more serious since it uses a weapon, though as the UCR subcategory of aggravated assault without a weapon clearly shows, aggravated assault does not require use of a weapon. Simple assault is first available in 1964. Index crime data is available since 1960. The FBIs report for arrests does include simple assault so the second reason people may not include it does not apply here. UCR data provides no information about the harm caused to victims. The new FBI dataset NIBRS actually does have a variable that includes harm to the victim so if youre interested in measuring harm (an understudied topic in criminology), that is the dataset to use. From 1960-2018, there were 39 agency-years with a negative count of murders. Jurisdiction here refers to the boundaries of the local government, not any legal authority for where the officer can make arrests. For example, the Los Angeles Police Departments jurisdiction in this case refers to crimes that happen inside the city or are otherwise investigated by the LAPD - and are not primarily investigated by another agency. Some states do mandate that their agencies report, but this is not always followed. This data is also sometimes called the Police Employees dataset. If youre familiar with the National Incident-Based Reporting System (NIBRS) data that is replacing UCR, this dataset is the closest UCR data to it, though it is still less detailed than NIBRS data. The first year where transgender as a group was a considered a bias motivation was in 2013. It also includes the value of items stolen during rapes and murders, if anything was stolen. I will refer to this an an ORI, ORI code, and ORI number, all of which mean the same thing. In the NIBRS data (another FBI data set) the ORI uses a 9-digit code - expanding the 5 numbers to 7 numbers. Since this isnt a programming book I wont include the code. For most fixed-width ASCII files there are also missing values where itll have placeholder value such as -8 and the setup file will instruct the software to convert that to NA. UCR data, however, does not have this and does not indicate when values are missing in this manner. For those interested in reading in this type of data, please see my R package asciiSetupReader. Even highly experienced programmers who are doing something like can make mistakes. For example, if you type out 2+2 100 times - something extremely simple that anyone can do - how often will you mistype a character and get a wrong result? Id guess that at least once youd make a mistake. With the exception of the arrest data and some value label changes in hate crimes and homicide data, the setup files remain consistent you a single file will work for all years for a given dataset. You do not need to make a setup file for each year. For evidence of this, please see any of the openICPSR pages for my detail as they detail changes Ive made in the data such as decisions on what level to aggregate to and mistakes that I made and later found and fixed. "],["offenses-known.html", "Chapter 3 Offenses Known and Clearances by Arrest 3.1 Which crimes are included? 3.2 Important variables 3.3 Number of months reported 3.4 Important issues", " Chapter 3 Offenses Known and Clearances by Arrest The Offenses Known and Clearances by Arrest dataset - often called Return A, Offenses Known or, less commonly, OKCA - is the oldest and most commonly used dataset and measures crimes reported to the police. For this reason it is used as the main measure of crime in the United States and I tend to call it the crimes dataset. This data includes the monthly number of crimes reported to the police or otherwise known to the police (e.g. discovered while on patrol) for a small selection of crimes, as well as the number of crimes cleared by arrest or by exceptional means (a relatively flawed and manipulable measure of whether the case is solved). It also covers the number reported but found by police to have not occurred. Since this data has monthly agency-level crime information it is often used to measure crime trends between police agencies and over time. The data uses something called a Hierarchy Rule which means that in incidents with multiple crimes, only the most serious is recorded - though in practice this affects only a small percent of cases, and primarily affects property crimes. 3.1 Which crimes are included? This data set contains information on the number of Index Crimes (sometimes called Part I crimes) reported to each agency. These index crimes are a collection of eight crimes that, for historical reasons based largely by perceived importance and reliable of their reporting in the 1920s when the UCR program was first developed, are used as the primary measure of crime today. Other data sets in the UCR, such as the Arrests by Age, Sex, and Race data and the Hate Crime data have more crimes reported. The crimes are, in order by the Hierarchy Rule (which well discuss next): Homicide Murder and non-negligent manslaughter Manslaughter by negligence Rape Rape Attempted rape Robbery With a firearm With a knife of cutting instrument With a dangerous weapon not otherwise specified Unarmed - using hands, fists, feet, etc. Aggravated Assault (assault with a weapon or causing serious bodily injury) With a firearm With a knife of cutting instrument With a dangerous weapon not otherwise specified Unarmed - using hands, fists, feet, etc. Burglary With forcible entry Without forcible entry Attempted burglary with forcible entry Theft (other than of a motor vehicle) Motor Vehicle Theft Cars Trucks and buses Other vehicles Arson Simple Assault Arson is considered an index crime but is not reported in this data - you need to use the separate Arson data set of the UCR to get access to arson counts. See Chapter 2.3.7 for an overview of the Arson data. The ninth crime on that list, simple assault, is not considered an index crime but is nevertheless included in this data. Each of the crimes in the list above, and their subcategories, are included in the UCR data. In most news and academic articles, however, youll see them reported as the total number of index crimes, summing up categories 1-7 and reporting that as crime. These index crimes are often divided into violent index crimes - murder, rape, robbery, and aggravated assault - and property index crimes - burglary, theft, motor vehicle theft. 3.1.1 Hierarchy Rule This dataset uses what is called the Hierarchy Rule where only the most serious crime in an incident is reported (except for motor vehicle theft and arson, which are always included). For example if there is an incident where the victim is robbed and then murdered, only the murder is counted as it is considered more serious than the robbery. That the data uses the Hierarchy Rule is an oft-cited (by academics, reporters, random people on Twitter) criticism of the data that are, in my opinion, overblown. In practice, the Hierarchy Rule has only modest effects on the data, undercounting few crimes. Though the Hierarchy Rule does mean this data is an under-count, data from other sources indicate that it isnt much of an under count. The FBIs other data set, the National Incident-Based Reporting System (NIBRS) contains every crime that occurs in an incident (i.e. it doesnt use the Hierarchy Rule). Using this we can measure how many crimes the Hierarchy Rule excludes (Most major cities do not report to NIBRS so what we find in NIBRS may not apply to them). In over 90% of incidents, only one crime is committed. Additionally, when people talk about crime they usually mean murder which, while incomplete to discuss crime, means the UCR data here is accurate on that measure. The FBI also released a report available here in 2015 that directly examined this issue by taking NIBRS data from 2014 and examined how NIBRS data (which includes all crimes) compares to using the Hierarchy Rule and keeping only the most serious crime. Figure @ref{fig:fbiHierarchy} is a screenshot from their report showing the percent increases in crimes when including all crimes in an incident relative to following the Hierarchy Rule. They find that 10.6% of incidents have multiple crimes occurring, which is similar to other years that I have examined myself. For violent crime, murder and rape have no change; for the remaining violent crimes - robbery and aggravated assault - crimes increased by 0.6%.24 Burglary increased by 1% and the largest increases came from theft and motor vehicle theft, increasing by 2.6% and 2.7%, respectively. Curiously motor vehicle theft increased even though the FBIs documentation for this data says that it is exempt from the Hierarchy Rule and should always be reported. This suggests either non-compliance or that the manual is incorrect. Figure 3.1: The FBIs findings of how crime reporting changes when using the Hierarchy Rule using NIBRS 2014 data. So using the Hierarchy Rule does undercount crime, but this is a small undercounting and is primarily led by property crime. Violent crime is only slightly undercounted. Please keep in mind that this is for crimes that the police record and is unaffected by outside decisions like what the district attorney charges or what the defendant is ultimately convicted of. 3.1.2 The problem with using index crimes The biggest problem with index crimes is that it is simply the sum of 8 (or 7 since arson data usually isnt available) crimes. Index crimes have a huge range in their seriousness - it includes both murder and theft. This is clearly wrong as 100 murders is more serious than 100 thefts. This is especially a problem as less serious crimes (theft mostly) are far more common than more serious crimes (in 2017 there were 1.25 million violent index crimes in the United States. That same year had 5.5 million thefts.). So index crimes under-count the seriousness of crimes. Looking at total index crimes is, in effect, mostly just looking at theft. This is especially a problem because it hides trends in violent crimes. San Francisco, as an example, has had a huge increase in index crimes in the last several years. When looking closer, that increase is driven almost entirely by the near doubling of theft since 2011. During the same years, violent crime has stayed fairly steady. So the city isnt getting more dangerous but it appears like it is due to just looking at total index crimes. Many researchers divide index crimes into violent and nonviolent categories, which helps but is still not entirely sufficient. Take Chicago as an example. It is a city infamous for its large number of murders. But as a fraction of index crimes, Chicago has a rounding error worth of murders. Their 653 murders in 2017 is only 0.5% of total index crimes. For violent index crimes, murder makes up 2.2%. What this means is that changes in murder are very difficult to detect. If Chicago had no murders this year, but a less serious crime (such as theft) increased slightly, we couldnt tell from looking at the number of index crimes. 3.2 Important variables For each crime we have four different categories indicating the number of crimes actually committed, the number cleared, and the number determined to not have occurred. 3.2.1 Actual crimes This is the number of offenses that occurred, simply a count of the number of crimes that month. For example if 10 people are murdered in a city the number of actual murders would be 10. 3.2.2 Total cleared crimers A crime is cleared when an offender is arrested or when the case is considered cleared by exceptional means. When a single offender for a crime is arrested, that crime is considered cleared. If multiple people committed a crime, only a single person must be arrested for it to be cleared, and as the UCR data is at the offense level, making multiple arrests for an incident only counts as one incident cleared. So if 10 people committed a murder and all 10 were arrested, it would report one murder cleared not 10. If only one of these people are arrested it would still report one murder cleared - the UCR does not even say how many people commit a crime. A crime is considered exceptionally cleared if the police can identify the offender, have enough evidence to arrest the offender, know where the offender is, but is unable to arrest them. Some examples of this are the death of the offender or when the victim refuses to cooperate in the case. Unfortunately, this data does not differentiate between clearances by arrest or by exceptional means. For a comprehensive report on how this variable can be exploited to exaggerate clearance rates, see this report by ProPublica on exceptional clearances with rape cases. 3.2.3 Crimes cleared Where all offenders are under 18 years old This variable is very similar to Total Cleared except is only for offenses in which every offender is younger than age 18. 3.2.4 Unfounded crimes An unfounded crime is one in which a police investigation has determined that the reported crime did not actually happen. For example I observed during a ride-along a report of a burglary where the homeowners said that they came home and the front door was open and they thought it might have been their son who forgot to close it but could also be a burglar so they called the police just in case. This would be recorded as a burglary and if it turned out to be the son, the police would then record this as an unfounded burglary. Other unfounded crimes would include when someone reports a crime but later says that the report wasnt true. For example, a person could report a burglary to the police to collect insurance money on the items they claim was stolen. If the police discover this they would unfound the case - and the lying to the police and fraud would not be counted as neither of those are crimes included in this dataset. Figure 3.2: The annual number of actual and unfounded rapes in Philadephia, PA, 1960-2018. Figure 3.3: The percent of reported rapes that the police recorded as unfounded in Philadephia, PA, 1960-2018. 3.3 Number of months reported UCR data is reported monthly though even agencies that decide to report their data may not do so every month. As we dont want to compare an agency which reports 12 months to one that reports fewer, the variable number_of_months_reported is way keep only agencies that report 12 months, or deal with those that report fewer. 3.4 Important issues 3.4.1 Rape definition change The FBI changed the definition of rape for UCR data starting in 2013 to a broader definition than the older definition, which is commonly called the legacy definition or legacy or historical rape. The legacy definition is the carnal knowledge of a female forcibly and against her will (emphasis added). This means that only rape is only included in UCR data when it is a female (or any age, there is no differentiation for child victims) forcibly vaginally penetrated by a penis. This is a narrow definition and excludes a number of sexual acts that people may consider rape such as forced oral or sex, and cases with a male victim. The new (and current) definition penetration, no matter how slight, of the vagina or anus with any body part or object, or oral penetration by a sex organ of another person, without the consent of the victim. Starting in 2013, rape has a new, broader definition in the UCR to include oral and anal penetration (by a body part or object) and to allow men to be victims. The new definition is: Penetration, no matter how slight, of the vagina or anus with any body part or object, or oral penetration by a sex organ of another person, without the consent of the victim. The previous definition included only forcible intercourse against a woman. This definition is far broader and is effectively any non-consensual sexual act. It also includes male victims though the data does not differentiate between male or female (or any other gender) victims. Both the current and legacy definitions exclude statutory rape and incest other than forcible incest. They both also include lack of consent as cases where the victim cannot give consent, such as if they are too young or are mentally or physically incapacitated - they specifically give the example of being temporarily incapacitated through drugs or alcohol. As this revised definition is broader than the original one post-2013, rape data is not comparable to pre-2013 data. 2013, however, is simply the year that the FBI changed the definition which means that agencies should have changed their reporting to the new definition. As might not be too surprising, not all agencies followed this requirement. Well look at four examples to show when there is clear evidence that the agency did change their definition in 2013, when its clear they did so a year later, when its unclear exactly when they made the change, and when the agency seems to not follow the change at all. Well start with the Philadelphia Police Department in Philadelphia, PA, shown in Figure 3.4 which shows the annual number of rapes from 2000-2018. Its declining slowly but steadily over the 2000-2012 time period until spiking sharply in 2013. Since the rape definition change in 2013 is far broader than previous years definition, this makes sense. A broader definition should lead to a sudden increase in reported rapes if the agency is reporting correctly. Figure 3.4: The annual number of rapes reported in Philadelphia, Pennsylvania, 2000-2018. In comparison, New York City has the sudden spike a year later, which indicates that they didnt start using the new definition until 2014. Figure 3.5 shows that rape is fairly steady, though increasing, in the years leading up to 2013 and has almost no change from 2012 to 2013, but a huge increase in 2014 and then steadily increases from there, spiking again in 2018. This seems like a fairly clear indicator that NYC simply didnt follow the new definition until 2014. Figure 3.5: The annual number of rapes reported in New York City, 2000-2018. Less clear is whats happening in San Francisco, California, shown in Figure 3.6. Here we do see an increase in 2013 which while it appears small on the graph is actually a 49% increase from 2012. Then there is a much larger spike in 2014 - a 120% increase - which may suggest that part of the agency started following the new definition in 2013 and the remainder followed in 2014. However, large increases or decreases are relatively common in San Francisco so it could also be that the agency only switched to the new definition in 2014 and the spike in 2013 is just a coincidence Figure 3.6: The annual number of rapes reported in San Francisco, California, 2000-2018. Finally, well look at Jackson Police Department in Mississippi where the definition change seems to have had no effect. As seen in Figure 3.7, reported rapes start to undulate in 2010 with 2013 data perfectly in line with the before and after trends - no sign that there is a change in reporting. This suggests that Jackson simply did not follow the definition change and continues to report using the old definition. Figure 3.7: The annual number of rapes reported in Jackson, Mississippi, 2000-2018. My takeaway from this is that rape should not be used at all for years after 2012. While the definition change makes pre-2013 and 2013+ years non-comparable, the differences in agency responses to this change - i.e. if they follow the rules or not - is such a mess that the data is too flawed to use. 3.4.2 The decline of manslaughter This data contains two different crime subcategories for homicide: murder and non-negligent manslaughter, and manslaughter by negligence. The first is our measure of murder, and it includes everything we traditionally think of when it comes to murder - shootings, stabbings, strangulation, basically any intentional killing of another person.25 Suicides, killing a fetus, and accidental killings (e.g. car crashes) are not considered murders.26 The second, manslaughter by negligence - usually called just manslaughter - is when someone kills another person through gross negligence but does not kill them intentionally. This can include accidental killings when the death was caused by gross negligence. The FBI provide examples of this as kids playing with guns and shooting each other (and not knowing the gun was loaded) or a hunter accidentally shooting someone while hunting. I would assume that manslaughter by negligence would remain at a relatively steady rate - though increasing in raw numbers as population increases - as it is due to largely unintentional behavior that would be unaffected by crime-reduction policies.27 I was wrong though. One of the most curiously findings from my exploration of this data is the sudden and national decline in manslaughter by negligence in the 1970s - and the extremely high number of manslaughter before that. Figure 3.8 shows the annual number of murders, manslaughter, and the sum of the two nationwide from 1960-2018. This just sums up the total reported counts from every agency each year so part of the increase is simply due to more agencies reporting as the year gets closer to the present day - so please pay attention to the diverging paths of each crime, not the trend for the individual crime over time. Murder is always more common than manslaughter Figure 3.8: The annual number of murder and non-negligent manslaughter, manslaughter by negligence, and the sum of the two, nationwide from 1960-2018. Figure 3.9 shows another way to look at this data: manslaughter as a percent of reported murder. In the early years of our data manslaughter was fairly common, with about 70-80% as many manslaughters reported as murders. This declined sharply in the mid-1960s until there were around 45% as many manslaughters as murders in the mid-1970s. Again this declined until it was about 4% in 1980, and it has remained around there ever since. Figure 3.9: Reported manslaughter by negligence as a percent of reported murder and non-negligent manslaughter, nationwide 1960-2018. Murder is not shown in this figure since murder is always reported so cannot change. Attempted murder is usually classified as an aggravated assault. Even the intentional killing of a fetus is classified as an aggravated assault against the mother, not a murder of the fetus. Though policies that encourage people to lock up their guns would likely reduce manslaughter by negligence. "],["arrests.html", "Chapter 4 Arrests by Age, Sex, and Race 4.1 A brief history of the data 4.2 What does the data look like? 4.3 What variables are in the data? 4.4 Known issues with the data 4.5 Final thoughts", " Chapter 4 Arrests by Age, Sex, and Race The Arrests by Age, Sex, and Race dataset - often called ASR or the arrests data - includes the monthly number of arrests for a variety of crimes and, unlike the crime data, breaks down this data by age and gender. This data includes a broader number of crime categories than the crime dataset (the Offenses Known and Clearances by Arrest data) though is less detailed on violent crimes since it does not breakdown aggravated assault or robberies by weapon type as the Offenses Known data does. For each crime it says the number of arrests for each gender-age group with younger ages (15-24) showing the arrestees age to the year (e.g. age 16) and other ages grouping years together (e.g. age 25-29, 30-34, under 10). It also breaks down arrests by race-age by including the number of arrestees of each race (American Indian, Asian, Black, and White) are the only included races) and if the arrestee is a juvenile (&lt;18 years old) or an adult. The data does technically include a breakdown by ethnicity-age (e.g. juvenile-Hispanic, juvenile-non-Hispanic) but almost no agencies report this data (for many years zero agencies report ethnicity) so in practice the data does not include ethnicity. As the data includes counts of arrestees, people who are arrested multiple times are included in the data multiple times - it is not a measure of unique arrestees. 4.1 A brief history of the data 4.1.1 Changes in definitions 4.2 What does the data look like? 4.2.1 Raw data 4.3 What variables are in the data? 4.3.1 Key variables 4.4 Known issues with the data 4.5 Final thoughts "],["leoka.html", "Chapter 5 Law Enforcement Officers Killed and Assaulted (LEOKA) 5.1 Common uses of this data 5.2 A brief history of the data 5.3 What does the data look like? 5.4 What variables are in the data? 5.5 Known issues with the data 5.6 Final thoughts", " Chapter 5 Law Enforcement Officers Killed and Assaulted (LEOKA) The Law Enforcement Officers Killed and Assaulted data, often called just by its acronym LEOKA, has two main purposes.28 First, it provides counts of employees employed by each agency - broken down by if they are civilian employees or sworn officers, and also broken down by gender. And second, it measures how many officers were assaulted or killed (including officers who die accidentally such as in a car crash) in a given month. The assault data is also broken down into shift type and type (e.g. alone, with a partner, on foot, in a car, etc.), the offenders weapon, and type of call they are responding to (e.g. robbery, disturbance, traffic stop). The killed data simply says how many officers are killed feloniously (i.e. murdered) or died accidentally (e.g. car crash) in a given month. The employee information is at the year-level so you know, for example, how many male police officers were employed in a given year at an agency, but dont know any more than that such as how many officers were on patrol, were detectives, were in special units, etc. This dataset is commonly used as a measure of police employees and is a generally reliable - though imperfect as well see - measure of how many police are employed by a police agency. The second part of this data, measuring assaults and deaths, is more flawed with missing data issues and data error issues (e.g. more officers killed than employed in an agency). 5.1 Common uses of this data This data, as well as the privately-run site Officer Down Memorial Page which covers law enforcement officers who have died, has also been used lately in the context of police using force against people out of fear of being harmed by that person. The discussion revolves around whether police are actually in high danger of being harmed by comparing the rate at which officers die to that of other professions. In general they find that police officers are among the most likely profession to die but are not at the top of this measure. 5.2 A brief history of the data 5.2.1 Changes in definitions 5.3 What does the data look like? 5.4 What variables are in the data? 5.4.1 Key variables 5.5 Known issues with the data 5.6 Final thoughts This data is also sometimes called the Police Employees dataset. "],["shr.html", "Chapter 6 Supplementary Homicide Reports (SHR) 6.1 A brief history of the data 6.2 What does the data look like? 6.3 What variables are in the data? 6.4 Known issues with the data 6.5 Final thoughts", " Chapter 6 Supplementary Homicide Reports (SHR) The Supplementary Homicide Reports dataset - often abbreviated to SHR - is the most detailed of the UCR datasets and provides information about the circumstances and participants (victim and offender demographics and relationship status) for homicides.29 For each homicide incident it tells you the age, gender, race, and ethnicity of each victim and offender as well as the relationship between the first victim and each of the offenders (but not the other victims in cases where there are multiple victims). It also tells you the weapon used by each offender and the circumstance of the killing, such as a lovers triangle or a gang-related murder. As with other UCR data, it also tells you the agency it occurred in and the month and year when the crime happened. ## [1] 30.96352 Figure 6.1: The age of homicide offenders, based on the first offender in any homicide incident. Victims under age 1 (classified as birth to 7 days old, including abandoned infant and 7 days to 364 days old) and considered 0 years old. Victims reported as 99 years or older are considered 99 years old. ## [1] 32.87052 Figure 6.2: The age of homicide offenders, based on the first offender in any homicide incident. Victims under age 1 (classified as birth to 7 days old, including abandoned infant and 7 days to 364 days old) and considered 0 years old. Victims reported as 99 years or older are considered 99 years old. Figure 6.3: The weapon used in a homicide incident. In cases where there are multiple offenders, shows only the primary weapon for the first offender. Figure 6.4: The relationship between the first victim and the first offender in a homicide incident. Figure 6.5: The circumstance of the homicide for the first offender in a homicide incident. Figure 6.6: The circumstance for the first offender in a homicide incident in cases where the offender is killed. This includes incidents where the only person who dies in the offender. While highly detailed compared to other UCR data, there are a number of limitations for this data. Since this data is voluntary to Figure 6.7: The annual number of murders from the Supplementary Homicide Report and the Offenses Known and Clearances by Arrest dataset. Numbers differ because agencies voluntarily report and may not report to both datasets. This If this most detailed dataset sounds disappointing - and it is! - 6.1 A brief history of the data The data is available from the FBI starting in 1975 though, unlike all later years, this year only has information on a single victim and a single offender. For this reason I only release data starting in 1976 where up to 11 victims and 11 offenders are included. This data has been released every year since and the most recent year available is 2019. 6.1.1 Changes in definitions 6.2 What does the data look like? 6.2.1 Raw data 6.3 What variables are in the data? 6.3.1 Key variables 6.4 Known issues with the data 6.5 Final thoughts If youre familiar with the National Incident-Based Reporting System (NIBRS) data that is replacing UCR, this dataset is the closest UCR data to it, though it is still less detailed than NIBRS data. "],["hate-crimes.html", "Chapter 7 Hate Crime Data 7.1 Agencies reporting 7.2 Important variables", " Chapter 7 Hate Crime Data This dataset covers crimes that are reported to the police and judged by the police to be motivated by hate More specifically, they are, first, crimes which were, second, motivated - at least in part - by bias towards a certain person or group of people because of characteristics about them such as race, sexual orientation, or religion. The first part is key, they must be crimes - and really must be the selection of crimes that the FBI collects for this dataset. Biased actions that dont meet the standard of a crime, or are of a crime not included in this data, are not considered hate crimes. For example, if someone yells at a Black person and uses racial slurs against them, it is clearly a racist action. For it to be included in this data, however, it would have to extend to a threat since intimidation is a crime included in this data but lesser actions such as simply insulting someone is not included. For the second part, the bias motivation, it must be against a group that the FBI includes in this data. When this data collection began crimes against transgender people were not counted so if a transgender person was assaulted or killed because they were transgender, this is not a hate crime recorded in the data.30 So this data is really a narrower measure of hate crimes than it might seem. In practice it is (some) crimes motivated by (some) kinds of hate that are reported to the police. It is also the most under-reported UCR dataset with most agencies not reporting any hate crimes to the FBI. This leads to huge gaps in the data with some states having zero agencies report crime, agencies reporting some bias motivations but not others, agencies reporting some years but not others. While these problems exist for all of the UCR datasets, it is most severe in this data. This problem is exacerbated by hate crimes being rare even in agencies that report them - with such rare events, even minor changes in which agencies report or which types of offenses they include can have large effects. My main takeaway for this data is that it is inappropriate to use for most hate crime research. At most it can be used to look at within-city within-bias-motivation trends, while keeping in mind that even this narrow subset of data is limited by under-reporting by victims and potential changes in police practices of reporting such as how many months of data they report per year. 7.1 Agencies reporting hate crime data is available from 1991 to 2019 - Figure 7.1: The annual number of police agencies that report at least one hate crime incident in that year. Another way to understand reporting is to look at the number of reported hate crimes by state and see which states report and which dont. Figure 7.2 does this for 2018 data by showing the number of reported hate crime incidents by state. While every state other than Wyoming reporting at least one hate crime in 2018, there are large differences between states because even in states that have reporting agencies, not all agencies in that state report. For example, Alabama reported only two hate crimes in 2018, the least of any state other than Wyoming. Figure 7.2: Total reported hate crimes by state, 2018. Since the number of state-wide hate crimes is partially influenced by population, well also look at it as the percent of agencies in the state that report at least one hate crime. Again this is limited by population as agencies in each state cover different populations - and most agencies are small so a few large agencies can account for a large share of crimes, including hate crimes. Still, this is a useful exercise as we can easily see where very few agencies report. Figure 7.3 shows the percent of agencies for each state that reported at least one hate crime in 2018. In Connecticut, the state with the highest percent of agencies reporting, 28% of agencies reported at least one hate crime. In 34 states, fewer than 10% of agencies reported a hate crime, and in 19 states fewer than 5% of agencies did so. One interesting finding from this graph is the more liberal states - Connecticut, New Jersey, Vermont, California, Washington - have the highest share of agencies reporting a hate crime, indicating that the culture of the state may influence whether agencies report hate crimes. Figure 7.3: The percent of agencies in each state that reported at least one hate crime in 2018. 7.2 Important variables Each hate crime incident can cover up to 10 different crimes occurring - e.g. a person who burglarizes a synagogue and spray paints a swastika on the wall would be have both vandalism and burglary reported in this data. With each crime, this data has the bias motivation for that crime, the location of the crime (in broad categories, not the actual location in the city like a street address would have), and the number of victims for that offense. In practice, in hate crimes with multiple offenses recorded, the bias motivation, location, and victim count is the same for each offense. 7.2.1 Bias motivation The most important variable in this data is the bias motivation which is the FBIs term for the cause of the hate. A hate crime targeted against Black people would be an anti-Black bias motivation. For the police to classify an incident as a hate crime, and to assign a particular bias motivation, the police must have some evidence that the crime was motivated by hate. The victim saying that the crime is a hate crime alone is not sufficient - though if large portions of the victims community believe that the crime is a hate crime, this is a factor in the polices assessment. The evidence required is not major, it includes things as explicit as racial slurs said during an incident and less obvious factors like the victim is celebrating their community (e.g. attending a holiday event) or the crime occurring on an important holiday for that community (e.g. Martin Luther King Day, religious holidays). The FBI also encourages police to consider the totality of the evidence even if none alone strongly suggests that the crime was a hate crime in making their determination about whether the incident was a hate crime or not. This also means that many (likely most) hate crimes will not be recorded as hate crimes since there is no evidence that the crime is motivated by hate. For example, if a man targeted Asian people for crimes because they are Asian, that would in reality be a hate crime. However, if the offender does not say anything anti-Asian to the victim, which is the mostly likely thing to indicate that this is a hate crime, the crime would not likely be recorded as a hate crime. Indeed, even if crimes against Asian people significantly increase, without evidence Bias motivation is based on the offenders perceptions of the victim so even if they are incorrect in who their victim is, if they intended to target someone for their perceived group membership, that is still a hate crime. For example, if a person assaults a man because they think he is gay, that is a hate crime because the assault was motivated by hate towards gay people. Whether the victim is actually gay or not is not relevant - the offender perceived him to be gay so it is an anti-gay hate crime. To make this even more complicated, the offender must have committed the crime because they are motivated, at least to some degree, by their bias against the victim. Being biased against the victim but targeting them for some other reason means that the crime is not a hate crime. Figure 7.4: The bias motivation for hate crime incidents. In incidents with multiple bias motivation, this shows only the first bias motivation recorded. 7.2.2 Which crime occurred Figure 7.5: The offense type for hate crime incidents. In incidents with multiple offense types, this shows only the first offense type recorded. 7.2.3 Location Figure 7.6: The location of hate crime incidents. In incidents with multiple locations, this shows only the first location recorded. 7.2.4 Number and race of offenders There are two variables that have information about the people who commit the hate crime: the number of offenders and the race of the offenders (as a single value with the race of the group if all are of the same race or it will say a multi-racial group). Unfortunately, important information like the age of the offenders, their criminal history, their relationship to the victim, their gender, or whether they are arrested are completely unavailable in this dataset. When the police do not have any information about the number of offenders (which is common in cases of property crimes such as vandalism but rare in violent crimes), this data considers that to have zero offenders. The zero is just a placeholder that means that the police have no idea how many offenders there are, not that they think there were actually no offenders. Figure 7.7 shows the percent of hate crimes from 1991-2018 that have each number of offenders recorded. In the actual data it says the actual number of offenders, with the largest group in the current data going to 99 offenders - in this graph I group 10 or more offenders together for simplicity. I also relabel zero offenders as Unknown offenders in the graph since thats more accurate. The most common number of offenders per hate crime is one offender, at about 46% of hate crimes from 1991-2018 having only one offender. This drops sharply to 9% of hate crimes having 2 offenders and continues to drop as the number of offenders increase. However, about a third (36.8%) of hate crimes have an unknown number of offenders. Figure 7.7: The race of offenders, as a group, for hate crime incidents, 1991-2018. The data also includes the race of the offenders as a group, though not the ethnicity (Hispanic or not) of the offenders. In cases where there are multiple races among offenders, that will be classified as a multi-racial group. As shown in Figure 7.7 The most common racial group is unknown since the police do not know the race of the offenders. Then are White offenders at nearly 40% of hate crimes followed by Black offenders at nearly 13% of hate crimes. The remaining racial groups are rare with about 2% of hate crimes being committed by a multi-racial group of offenders and 0.72% of hate crimes committed by Asian or Pacific Islander offenders and 0.54% committed by American Indian or Native Alaskan offenders. Figure 7.8: The race of offenders, as a group, for hate crime incidents, 1991-2018. The first year where transgender as a group was a considered a bias motivation was in 2013. "],["stolen-property.html", "Chapter 8 Property Stolen and Recovered (Supplement to Return A) 8.1 A brief history of the data 8.2 What does the data look like? 8.3 What variables are in the data? 8.4 Known issues with the data 8.5 Final thoughts", " Chapter 8 Property Stolen and Recovered (Supplement to Return A) The Property Stolen and Recovered data - sometimes called the Supplement to Return A (Return A being another name for the Offenses Known and Clearances by Arrest dataset, the crime dataset) - provides monthly information about property-related offenses (theft, motor vehicle theft, robbery, and burglary), including the location of the offense (in broad categories like gas station or residence), what was stolen (e.g. clothing, livestock, firearms), and how much the stolen items were worth.31 Therecovered\" part of this dataset covers the type and value of property recovered so you can use this, along with the type and value of property stolen, to determine what percent and type of items the police managed to recover. Like other UCR datasets this is at the agency-month level so you can, for example, learn how often burglaries occur at the victims home during the day, and if that rate changes over the year or differs across agencies. The data, however, provides no information about the offender or the victim (other than if the victim was an individual or a commercial business [based on the location of the incident - bank, gas station, etc]). The value of the property stolen is primarily based on the victims estimate of how much the item is worth (items that are decreased in value once used - such as cars - are supposed to be valued at the current market rate, but the data provides no indication of when it uses the current market rate or the victims estimate) so it should be used as a very rough estimate of value. 8.1 A brief history of the data 8.1.1 Changes in definitions 8.2 What does the data look like? 8.2.1 Raw data 8.3 What variables are in the data? 8.3.1 Key variables 8.4 Known issues with the data 8.5 Final thoughts It also includes the value of items stolen during rapes and murders, if anything was stolen. "],["arson-1.html", "Chapter 9 Arson 9.1 Agencies reporting 9.2 Important variables 9.3 Types of arsons 9.4 Data errors", " Chapter 9 Arson The arson dataset provides monthly counts at the police agency-level for arsons that occur, and includes a breakdown of arsons by the type of arson (e.g. arson of a persons home, arson of a vehicle, arson of a community/public building) and the estimated value of the damage caused by the arson. This data includes all arsons reported to the police or otherwise known to the police (e.g. discovered while on patrol) and also has a count of arsons that lead to an arrest (of at least one person who committed the arson) and reports that turned out to not be arsons (such as if an investigation found that the fire was started accidentally). For each type of arson it includes the number of arsons where the structure was uninhabited or otherwise not in use, so you can estimate the percent of arsons of buildings which had the potential to harm people. This measure is for structures where people normally did not inhabit the structure - such as a vacant building where no one lives. A home where no one is home at the time of the arson does not count as an uninhabited building. In cases where the arson led to a death, that death would be recorded as a murder on the Offenses Known and Clearances by Arrest dataset - but not indicated anywhere on this dataset. If an individual who responds to the arson dies because of it, such as a police officer or a firefighter, this is not considered a homicide (though the officer death is still included in the Law Enforcement Officers Killed and Assaulted data) unless the arsonists intended to cause their deaths. Even though the UCR uses the Hierarchy Rule, where only the most serious offense that occurs is recorded, all arsons are reported - arson is exempt from the Hierarchy Rule. 9.1 Agencies reporting Figure 9.1 shows the annual number of police agencies that reported at least one month that year. With data starting in 1979, there were a little over 12,000 agencies reporting a year until the early 2000s where it recovered from a sharp drop in agencies to steadily increase to about 16,000 a year. While arson data is available through 2019, this graph only shows data through 2018. Figure 9.1: The annual number of police agencies that report at least month of data that year. 9.2 Important variables Similar to the Offenses Known and Clearances by Arrest data, which is covered in Chapter @ref(offenses_known), this data shows the monthly number of crimes - in this case only arsons - reported or discovered by the police, the number found by police to be unfounded, and the number cleared by the police. In addition, it includes the number of arsons in structures that were uninhabited, and the estimated cost of the damage caused by the arsons. For each variable, the arsons also broken into several categories of arsons, which well talk about in Section 9.3. Like other UCR data, there are also variables that provide information about the agency - ORI codes, population under jurisdiction - the month and year that the data covers, and how many months reported data. 9.2.1 Actual arsons This variable includes the number of arsons either reported to the police or otherwise known to the police in that month and that the police determine to actually be arsons - that is, reports that are not unfounded. This is based only on the polices determination that an arson occurred, not the decision of other groups like a court or the conviction of someone for the crime. 9.2.2 Unfounded arsons This variable shows the number of arsons reports that the police determined to not actually be arsons. For example, if a house burns down and police think it was arson but later determine that it was an accident, it would be an unfounded arson. 9.2.3 Reported arsons This variable is the sum of actual arsons and unfounded arsons - it is the total number of arsons that were reported or known to the police, even if a later investigation found that it wasnt actually an arson. Since this is the sum of two already present variables - and is less informative than the two variables are as separate variables - Im not exactly sure why its included. 9.2.4 Cleared arsons This shows the number of arsons where at least one offender is arrested or when an arrest cannot be made for some reason but the police know who the offender is - the latter option is called exceptional clearances or clearances by exceptional means. There is no way to tell if an clearance is due to an arrest or due to exceptional means.32. For exceptional clearances, police must have identified the offender, have sufficient evidence to arrest that offender, know where they are (so they can actually be apprehended) and only then be unable to make the arrest. Exceptional clearances include cases where the offender dies before an arrest (by any means, including suicide, accidental, illness, killed by someone including a police officer) or when the police are unable to arrest the person since they are already in custody by another jurisdiction (including out of the country or in custody of another agency) and extradition is denied. Two other potential causes of exceptional clearance is when prosecution of the case cannot go forward because the district attorney refuses to prosecute the case, for reasons other than lack of evidence, or when a victim refuses to assist the prosecution in the case. Please note that this data is at the incident-level which means that having multiple people arrested for an incident still only is a clearance for that single incident. Clearances are also reported in the month they occur, not in the month that the initial crime happened. This can lead to cases where there are more clearances than crimes, incorrectly leading to the conclusion that police solve &gt;100% of crimes. Figure 9.2 shows the number of actual arsons (reports that are founded) and clearances for single-family home arsons in League City, Texas, a city of about 100,000 outside of Houston. In most years there were fewer clearances than arsons, but in four years (1982, 1981, 1992, and 2007) there were more clearances than arsons. This is simply because clearances are reported in the month they occur, regardless of when the arson they are clearance occurred. Figure 9.2: The annual number of single-family home arsons and clearances in League City, Texas. It is rare that there are more clearances than crimes in a given month though this is partially just due to few cases every being cleared. According to the 2019 NIBRS, it takes on average 7 days between the incident and the arrest (median = 0 days) for all crimes, and an average of 11.6 days from incident to arrest for arsons specifically (median = 0 days) for offenders who get arrested. This means that most clearances will be for crimes committed that month, though certainly not all. Therefore, use caution when trying to use this variable to measure crime clearance rates. 9.2.5 Cleared for arsons where all offenders are under age 18 This variable is the same for normal clearances but only for arsons where every offender is under the age of 18. In these cases a clearance by arrest can include citing the juvenile offender with an order to go to court to stand trial, even if the juvenile is not actually taken into police custody. As this variable requires that the police know every offender (to be able to determine that they are all under 18), it is likely highly flawed and not a very useful variable to use. 9.2.6 Uninhabited building arsons This data also includes the number of arsons that occur in uninhabited structures. These structures must be uninhabited in the long-term, not simply having no one inside them when the arson occurs. The FBI defines these are structures that are uninhabited, abandoned, deserted, or not normally in use. at the time of the arson. For example, a vacation home whose owners arent living in at the time would be not normally in use so would be an uninhabited building. A business that is closed when the fire started, but is open during the day, is not an uninhabited building. 9.2.7 Estimated damage cost The final variable is the estimated cost of the arson. This is how much the police estimates the value (in dollars) of the damaged or destroyed property is. Since this is the value of property damage, injuries to people (including non-physical injuries such as trauma or mental health costs) are not included. Since this is estimated damage it may be inaccurate to some degree. This variable is the sum of monthly estimated cost so while you can get the average cost by dividing this by the number of actual offenses, this average may be significantly off due to having extremely small or large values in your data. This value may be $0 since arsons include attempted arsons which may cause little or no damage. Please note that this value is not inflation-adjusted so you will have to adjust the value yourself. 9.3 Types of arsons For each of the arson categories above, this dataset has information for ten different types of arson. The type is based on where the arson occurred, not based on how the fire was initiated, how far or fast it spread, or any other information about the arson - nothing is actually known about the arson outcome other than if the arson was cleared and the estimated damage. There are seven arsons types for buildings, two for vehicles, and one as an other category that includes arsons of outdoor areas like parks or forests (though this group does not have any subcategories so all you know is the arson is neither of a building or a vehicle). For both the buildings and the vehicle arson types there is also a total buildings and total vehicles category that is just the sum of each subcategory; there is also a grant total variable that sums all building, vehicle, and other arsons. Building arsons Single occupancy home Other residential Storage Industrial/manufacturing building Other commercial building Community or public building All other structures Vehicles Motor vehicles Other vehicles All other arsons Some arsons can burn down multiple types or structures or cars - fire, after all, tends to spread. This data defines the arson based on where the fire originated. So an arson that starts in someones house and also burns down their car in the garage would be a single-family home arson, not a vehicle arson. This is true even if the damage is more severe for a type other than where the fire started. So if someone threw a Molotov cocktail at a car parked outside a house and it lightly damaged the car but spread to homes nearby and destroyed those homes, it is still a vehicle arson (though the damage recorded would include the homes burned.) 9.4 Data errors Like the other UCR data, there are some cases where there are obvious data entry errors leading to impossible numbers of reported arsons or the price of an arson. As an example, Figure 9.3 shows the annual number of single-family home arsons in Byron City, Illinois, which has a population of slightly over 3,600 people. Every year with data available there are zero arsons reported until 2003 when 469 arsons are reported. Since it is exceedingly unlikely that suddenly an eighth of the city suddenly burned down, and the city never again had a residence arson, this is almost certainly a data entry error. As arsons are relatively rare, having errors - and especially ones like this - can drastically change the results of your analysis so it is important to check your data carefully for more errors. For those using the data that I have cleaned and concatenated, the complete list of obvious outliers that I removed is available on the datas page on openICPSR. Figure 9.3: Annual single-family home arsons in Byron City, Illinois. The sudden spike to over 400 arsons in a single year is an example of data errors in this dataset. There are also cases where it is less clear when a value is a data error or is simply due to an outlier - but real - value. For example, Figure 9.4 shows the annual average cost of a single-family home fire in Los Angeles, California. In most years the damage is low - since an arson can damage only part of the house, these low values likely mean that on average only part of the house was damaged, not the entire house. In 2009, however, the average damage is about $540,000 per arson. Is this a data entry error that simply inputs a damage value that is too high? Its certainly possible. However, it could also be that some extraordinarily expensive homes were destroyed that year. In 2009 Los Angeles only reported 63 single-family home arsons so having one, or a few, super mansions - which LA has plenty of - destroyed could mean that this huge value is real. Figure 9.4: The annual average cost per single-family home arson in Los Angeles, California. NIBRS data does tell more information about the type of arrest, but UCR data does not "],["county-level.html", "Chapter 10 County-Level Detailed Arrest and Offense Data 10.1 A brief history of the data 10.2 What does the data look like? 10.3 What variables are in the data? 10.4 Final thoughts", " Chapter 10 County-Level Detailed Arrest and Offense Data 10.1 A brief history of the data 10.1.1 Changes in definitions 10.2 What does the data look like? 10.2.1 Raw data 10.2.2 Cleaned data 10.3 What variables are in the data? 10.3.1 Key variables 10.3.2 Known issues with the data 10.4 Final thoughts "],["references.html", "References", " References Bennice, Jennifer A, and Patricia A Resick. 2003. Marital Rape: History, Research, and Practice. Trauma, Violence, &amp; Abuse 4 (3): 22846. Devito, Lee. 2020. Marijuana Arrests on the Decline but Still Outnumber Violent Crime Arrests, According to FBI Data. City Beat; https://www.citybeat.com/news/blog/21145113/marijuana-arrests-on-the-decline-but-still-outnumber-violent-crime-arrests-according-to-fbi-data. Earlenbaugh, Emily. 2020. More People Were Arrested for Cannabis Last Year Than for All Violent Crimes Put Together, According to FBI Data. Forbes; https://www.forbes.com/sites/emilyearlenbaugh/2020/10/06/more-people-were-arrested-for-cannabis-last-year-than-for-all-violent-crimes-put-together-according-to-fbi-data/?sh=7dd59ad6122f. Edwards, Ezekiel, Emily Greytak, Brooke Madubuonwu, Thania Sanchez, Sophie Beiers, Charlotte Resing, Paige Fernandez, and Galai Sagiv. 2020. A Tale of Two Countries: Racially Targeted Arrests in the Era of Marijuana Reform. American Civil Liberties Union; https://www.aclu.org/report/tale-two-countries-racially-targeted-arrests-era-marijuana-reform. Ingraham, Christopher. 2016. Police Arrest More People for Marijuana Use Than for All Violent Crimes  Combined. The Washington Post; https://www.washingtonpost.com/news/wonk/wp/2016/10/12/police-arrest-more-people-for-marijuana-use-than-for-all-violent-crimes-combined/. Kertscher, Tom. 2019. More Arrests in the US for Marijuana Possession Than Violent Crimes, 2020 Hopeful Cory Booker Says. Politifact; https://www.politifact.com/factchecks/2019/jul/11/cory-booker/more-arrests-us-marijuana-possession-violent-crime/. McMahon-Howard, Jennifer, Jody Clay-Warner, and Linda Renzulli. 2009. Criminalizing Spousal Rape: The Diffusion of Legal Reforms. Sociological Perspectives 52 (4): 50531. Neusteter, S Rebecca, and Megan OToole. 2019. Every Three Seconds: Unlocking Police Data on Arrests. Very Institute of Justice; https://www.vera.org/publications/arrest-trends-every-three-seconds-landing/arrest-trends-every-three-seconds/overview. Speri, Alice. 2019. Police Make More Than 10 Million Arrests a Year, but That Doesnt Mean Theyre Solving Crimes. The Intercept; https://theintercept.com/2019/01/31/arrests-policing-vera-institute-of-justice/. "]]
